<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>变分推断</title>
    <link href="/2023/02/28/VariationalInference/"/>
    <url>/2023/02/28/VariationalInference/</url>
    
    <content type="html"><![CDATA[<h1 id="生成类模型">1 生成类模型</h1><p><a id="sec1"></a></p><p>深度学习模型总体来讲可以概括为判别类模型（Discriminative）和生成类模型（Generative）。对于样本集合<span class="math inline">\(\mathcal{X}=\{X^{(1)}, X^{(2)}, \cdots, X^{(n)}, \cdots\}\)</span>，判别类模型主要是输出每个样本对应的标签，而生成类模型则会度量样本的分布<span class="math inline">\(P(X)\)</span>并能够生成新的样本。</p><p>生成类模型在生成数据时可以使用Latent Variable Model。因为相同类别的数据在不同的维度之间存在依赖。以生成手写数字为例，在生成手写数字5时，如果已经生成了数字5的左半部分，即使没有右半部分，也可以判定是数字5. 因此，生成类模型在生成数据时可以考虑两个步骤，<strong>第一步决定生成什么数字，这个数字使用隐变量<span class="math inline">\(z\)</span>表示，第二步根据<span class="math inline">\(z\)</span>生成对应的数字</strong>。该过程可以表示如下： <span class="math display">\[P(X) = \int P(X|z;\theta)P(z)dz \tag{1}\]</span></p><p>在这个过程中，度量隐变量<span class="math inline">\(z\)</span>的分布是困难的，因为在深度学习背景下，生成的数据维度很高，不同维度之间可能存在依赖。VAE假定任意隐变量<span class="math inline">\(z\)</span>可以从一个标准正态分布中得到，并通过一个足够复杂的函数映射将隐变量映射为任意一个分布。如图1所示，我们可以利用函数 <span class="math inline">\(g(z)=\frac{z}{10} + \frac{z}{||z||}\)</span> 将一个二维高斯分布映射为环形。 <img src="/2023/02/28/VariationalInference/DimensionTrans.png" alt="图1 隐变量的维度映射"></p><h1 id="vae">2. VAE</h1><h2 id="vae基本思想">2.1 VAE基本思想</h2><p>根据<a href="#sec1">章节1</a>，我们可以看出，只要有足够强大的函数估计器，我们就可以得到任意分布的隐含变量<span class="math inline">\(z\)</span>，因此，我们可以使用神经网络来构建这个函数估计器。从而最大化公式（1）。</p><p>当有了隐变量<span class="math inline">\(z\)</span>的先验分布，很容易想到使用多次采样的方式来最大化似然函数 <span class="math display">\[P(X) \approx \frac{1}{n} \sum_{i=1}^{n} P(X^{(i)}|z^{(i)}) \tag{2}\]</span> 但是这种方法在高维空间十分低效。</p><p>为此，VAE并没有使用<span class="math inline">\(P(z)\)</span>（先验分布）是正态分布的假设，而假设<span class="math inline">\(P(z|X^{(i)})\)</span>（后验分布）是正态分布。具体来讲，对于任意真实样本<span class="math inline">\(X^{(i)}\)</span>，我们假设存在一个专属于 <span class="math inline">\(X^{(i)}\)</span> 的多元正态分布。强调专属是因为后面要训练一个生成器<span class="math inline">\(X=g(z)\)</span>，希望能够把从分布<span class="math inline">\(P(z|X)\)</span>中采样的<span class="math inline">\(z^i\)</span>还原为<span class="math inline">\(X^{(i)}\)</span>。如果直接假设<span class="math inline">\(P(z)\)</span>服从正态分布并随便采样出一个<span class="math inline">\(z\)</span>，那样就无法知道这个采样出的<span class="math inline">\(z\)</span>对应于哪个真实样本。而现在<span class="math inline">\(P(z|X^{(i)})\)</span>专属于样本<span class="math inline">\(X^{(i)}\)</span>，这样就有充分的理由认为从这个样本中采样出的<span class="math inline">\(z\)</span>应当还原为样本<span class="math inline">\(X^{(i)}\)</span>。</p><p>这样一来，每一个样本 <span class="math inline">\(X^{(i)}\)</span> 都配备了一个专属的正态分布以方便后面的生成器做还原。这样一来有多少样本就会有多少个正态分布了。为此，我们需要求解正态分布的两组参数，均值 <span class="math inline">\(\mu\)</span> 和方差 <span class="math inline">\(\sigma^2\)</span>。这两个参数可以通过神经网络来拟合出来，分别构建两个神经网络来拟合 <span class="math inline">\(\mu^{(i)} = f_1 (X^{(i)})\)</span> 和 <span class="math inline">\(\log {\sigma^{(i)}}^2 = f_2 (X^{(i)})\)</span>。这里选择拟合 <span class="math inline">\(\log \sigma^2\)</span> 而不是直接拟合 <span class="math inline">\(\sigma^2\)</span> 是因为后者总是非负的，需要加激活函数，而前者不需要，因为它可正可负。这样一来，我们就可以知道专属于样本 <span class="math inline">\(X^{(i)}\)</span> 的正态分布的均值和方差，从这个专属分布中采样出一个 <span class="math inline">\(z^{(i)}\)</span>，并经过生成器得到 <span class="math inline">\(\hat{X^{(i)}} = g(z^{(i)})\)</span>。如此，就可以最小化 <span class="math inline">\(D(X^{(i)}, \hat{X^{(i)}})^2\)</span> 来优化VAE。</p><h2 id="分布标准化">2.2 分布标准化</h2><p>在重构样本 <span class="math inline">\(X\)</span>，最小化 <span class="math inline">\(D(X^{(i)}, \hat{X^{(i)}})^2\)</span> 的过程中受到噪声的影响，因为 <span class="math inline">\(z^{(i)}\)</span> 是通过重新采样过的，而不是经过Encoder计算出来的。采样过程的噪声显然会增加模型重构的难度，好在噪声强度（也就是方差）是通过神经网络计算出来的，所以最终模型为了能够重构的更好，肯定会想尽办法让方差为0。但是如果方差为0的话，就没有随机性了，不管如何采样都只能得到确定性的结果，这样一来模型就会退化成普通的AutoEncoder，噪声不再起作用。</p><p>VAE让所有 <span class="math inline">\(P(z|X)\)</span> 都向标准正态分布看齐，这样就防止了噪声为0，同时保证了模型具有生成能力。如果所有的 <span class="math inline">\(P(z|X)\)</span> 都接近标准正态分布 <span class="math inline">\(\mathcal{N}(0, I)\)</span> ，那么根据定义，我们可以得到 <span class="math display">\[P(z)=\sum_{X}P(Z|X)P(X)=\sum_{X}\mathcal{N}(0,I)P(X)=\mathcal{N}(0,I)\sum_{X}P(X)=\mathcal{N}(0,I) \tag{3}\]</span> 这样就能达到我们的先验假设，<span class="math inline">\(P(z)\)</span>是标准正态分布。然后就可以放心地从 <span class="math inline">\(\mathcal{N}(0,I)\)</span> 中采样来生成样本了。</p><figure><img src="/2023/02/28/VariationalInference/VAEArch.png" alt="图2 VAE的架构"><figcaption aria-hidden="true">图2 VAE的架构</figcaption></figure><p>图2就是VAE的整体思路，先通过均值方差模块计算出每个样本 <span class="math inline">\(X^{(i)}\)</span> 对应的均值方差，再将其变换为标准正态分布，从标准正态分布中采样出隐变量 <span class="math inline">\(z^{(i)}\)</span>，再通过生成器产生对应的样本 <span class="math inline">\(\hat{X^{(i)}}\)</span>。</p><h2 id="使用kl散度使-pzx-接近-mathcaln0i">2.3 使用KL散度使 <span class="math inline">\(P(z|X)\)</span> 接近 <span class="math inline">\(\mathcal{N}(0,I)\)</span></h2><p>如果想要使所有 <span class="math inline">\(P(z|X)\)</span> 都尽可能接近 <span class="math inline">\(\mathcal{N}(0,I)\)</span>，最直接的方法是在重构误差的基础上加入额外的Loss <span class="math display">\[\mathcal{L}_\mu = ||f_1(X^{(i)})||^2 \text{ 和 } \mathcal{L}_{\sigma^2} = ||f_2(X^{(i)})||^2 \tag{4}\]</span> 但这样的方法会面临着两个损失比例如何选取的问题。因此，可以直接计算正态分布于标准正态分布的KL散度作为额外Loss。由于我们考虑的是各个分量独立的多元正态分布，因此只需要推导一元正态分布的情形即可，根据定义，我们可以写出： <span class="math display">\[\begin{split}&amp; KL\left(\mathcal{N}(\mu, \sigma^2)|| \mathcal{N}(0,1)\right) = \int \mathcal{N}(\mu, \sigma^2) \log \frac{\mathcal{N}(\mu, \sigma^2)}{\mathcal{N}(0,1)}dX \\&amp;= \int \frac{1}{\sqrt{2\pi\sigma^2}} \exp \left(-\frac{(X-\mu)^2}{2\sigma^2}\right) \left( \log \frac{\frac{1}{\sqrt{2\pi\sigma^2}} \exp \left(-\frac{(X-\mu)^2}{2\sigma^2}\right)}{\frac{1}{\sqrt{2\pi} \exp \left( -\frac{X^2}{2} \right) }} \right) dX \\&amp;= \int \frac{1}{\sqrt{2\pi\sigma^2}} \exp \left(-\frac{(X-\mu)^2}{2\sigma^2}\right) \log \left( \frac{1}{\sqrt{\sigma^2}} \exp \left( \frac{1}{2} \left[X^2 - \frac{(X-\mu)^2}{\sigma^2}\right] \right) \right) dX \\&amp;= \frac{1}{2} \int \frac{1}{\sqrt{2\pi\sigma^2}} \exp \left(-\frac{(X-\mu)^2}{2\sigma^2}\right) \left[ -\log \sigma^2 + X^2 - \frac{(X-\mu)^2}{\sigma^2} \right]dX\end{split} \tag{5}\]</span> 公式（5）可以看作是三项积分。第一项可以看作是 <span class="math inline">\(-\log \sigma^2\)</span> 乘以概率密度积分，概率密度的积分为1，因此第一项的结果为 <span class="math inline">\(-\log \sigma^2\)</span>。 第二项是 <span class="math inline">\(X^2\)</span> 乘以概率密度积分，实际上是正态分布的二阶矩，根据二阶矩的定义，可以知道第二项为 <span class="math inline">\(\mu^2 + \sigma^2\)</span>。第三项相当于是在第二项的基础上减去均值再除以方差，因此根据二阶矩的变换可以得到第三项为 -1.因此，公式（5）可以变换为： <span class="math display">\[\begin{split}\mathcal{L}_{\mu, \sigma^2} &amp;= KL\left(\mathcal{N}(\mu, \sigma^2)|| \mathcal{N}(0,1)\right) \\&amp;= \frac{1}{2} \sum_{j=1}^{d} \left({\mu_j^{(i)}}^2 + {\sigma_j^{(i)}}^2 - \log {\sigma_j^{(i)}}^2 - 1 \right) \end{split} \tag{6}\]</span> 公式（6）中 <span class="math inline">\(d\)</span> 是隐变量 <span class="math inline">\(z\)</span> 的维度，<span class="math inline">\(j\)</span>表示第<span class="math inline">\(j\)</span>维分量。</p><blockquote><p><strong>正态分K阶矩</strong> <span class="math display">\[\begin{split} E(X) &amp;= \int_{-\infty}^{\infty} x \frac{1}{\sqrt{2\pi}\sigma} \exp(-\frac{(x-\mu)^2}{2\sigma^2}) dx \\  &amp;= \int_{-\infty}^{\infty} (x-\mu+\mu) \frac{1}{\sqrt{2\pi}\sigma} \exp(-\frac{(x-\mu)^2}{2\sigma^2}) d(x-\mu) \\ &amp;= \int_{-\infty}^\infty \frac{t}{\sqrt{2\pi}\sigma} \exp(-\frac{t^2}{2\sigma^2})dt  + \mu \int_{-\infty}^\infty \frac{1}{\sqrt{2\pi}\sigma} \exp(-\frac{(x-\mu)^2}{2\sigma^2}) dx \\ &amp;= 0 + \mu \cdot 1 = \mu \end{split}\]</span> 根据方差的定义，<span class="math inline">\(Var(X) = \left[X-E(X)\right]^2 = E(X^2) - 2E(X)^2 + E(X)^2 = E(X^2)-E(X)^2\)</span>, 因此可得 <span class="math inline">\(E(X^2) = \sigma^2 + \mu^2\)</span>。</p></blockquote><h2 id="重参数技巧">2.4 重参数技巧</h2><p>重参数化英文名为Reparameterization Trick。如果我们从分布 <span class="math inline">\(P(z|X^{(i)})\)</span> 中采样一个 <span class="math inline">\(z^{(i)}\)</span> 出来，尽管我们知道 <span class="math inline">\(P(z|X^{(i)})\)</span> 是正态分布，但是采样过程不可导。为了使采样结果是可导的，令 <span class="math inline">\(\frac{(z-\mu)}{\sigma} = \epsilon\)</span>，这样一来 <span class="math inline">\(\epsilon\)</span> 就是服从 <span class="math inline">\(\mathcal{N}(0,I)\)</span> 标准正态分布。因此，从 <span class="math inline">\(\mathcal{N}(0,I)\)</span> 中采样 <span class="math inline">\(z\)</span> 相当于从 <span class="math inline">\(\mathcal{N}(\mu,\sigma^2)\)</span> 中采样一个 <span class="math inline">\(\epsilon\)</span>，然后让 <span class="math inline">\(z = \mu + \epsilon \times \sigma\)</span>。这样一来，采样操作就不用参与梯度下降了，改为采样的结果参与，这样就使得整个模型可以训练了。</p><h1 id="贝叶斯视角下的vae">3. 贝叶斯视角下的VAE</h1><h2 id="联合分布导出">3.1 联合分布导出</h2><p>对于原有的样本概率分布 <span class="math inline">\(P(X,z)\)</span> 和生成的样本概率分布 <span class="math inline">\(Q(X,z)\)</span>，我们使用KL散度来最小化它们之间的差异。 <span class="math display">\[\begin{split} &amp; KL(P(X,z)||Q(X,z)) = \int \int P(X,z) \log \frac{P(X,z)}{Q(X,z)} dz dX \\&amp;= \int \int P(z|X)P(X) \log \frac{P(z|X)P(X)}{Q(X|z)Q(z)} dz dX \\&amp;= \int P(X) \left[ \int P(z|X) \log \frac{P(z|X)P(X)}{Q(X|z)Q(z)} dz \right] dX \\&amp;= \mathbb{E}_{X\sim P(X)} \left[ \int P(z|X) \log \frac{P(z|X)P(X)}{Q(X|z)Q(z)} dz \right] \\&amp;= \mathbb{E}_{X\sim P(X)} \left[ \int P(z|X) \left( \log P(X) + \log \frac{P(z|X)}{Q(X|z)Q(z)} \right) dz \right] \\&amp;= \mathbb{E}_{X\sim P(X)} \left[\int P(z|X)\log P(X) dz\right] + \mathbb{E}_{X\sim P(X)} \left[ \int P(z|X) \log \frac{P(z|X)}{Q(X|z)Q(z)} dz\right] \\&amp;= \mathbb{E}_{X\sim P(X)} \left[\log P(X) \int P(z|X) dz\right] + \mathbb{E}_{X\sim P(X)} \left[ \int P(z|X) \log \frac{P(z|X)}{Q(X|z)Q(z)} dz\right] \\&amp;= \mathbb{E}_{X\sim P(X)} \left[ \log P(X) \right] + \mathbb{E}_{X\sim P(X)} \left[ \int P(z|X) \log \frac{P(z|X)}{Q(z)} dz - \int P(z|X) \log Q(X|z) dz \right] \\&amp;= \mathbb{E}_{X\sim P(X)} \left[ \log P(X)\right] + \mathbb{E}_{X\sim P(X)} \left[ KL(P(z|X)||Q(z)) - \mathbb{E}_{X\sim P(z|X)} [\log Q(X|z)] \right]\end{split}\tag{7}\]</span></p><p>对式（7）进行移项，可以得到 <span class="math display">\[\begin{split}&amp; \mathbb{E}_{X\sim P(X)} [\log P(X)] - KL(P(X,z)||Q(X,z)) \\&amp;= \mathbb{E}_{X\sim P(X)} [\mathbb{E}_{X\sim P(z|X)}[\log Q(X|z)] - KL(P(z|X)||Q(z))] \end{split}\tag{8}\]</span> 式（8）左侧第一项是要最大化似然概率，第二项要使KL散度最小，因此等同于最大化左侧。那么优化目标就转换成了最大化右侧，也就是ELBO。</p><blockquote><p><strong>ELBO</strong> <span class="math display">\[\begin{split} \log p(x) &amp;= \log p(x) \int q(z|x) dz = \int q(z|x) (\log p(x)) dz \\ &amp;= \mathbb{E}_{q(z|x)} [\log p(x)] = \mathbb{E}_{q(z|x)} \left[ \log \frac{p(x,z)}{p(z|x)} \right] \\ &amp;= \mathbb{E}_{q(z|x)} \left[ \log \frac{p(x,z) q(z|x)}{p(z|x) q(z|x)} \right] \\ &amp;= \mathbb{E}_{q(z|x)} \left[ \log \frac{p(x,z)}{q(z|x)} \right] + \mathbb{E}_{q(z|x)} \left[ \log \frac{q(z|x)}{p(z|x)} \right] \\ &amp;= \mathbb{E}_{q(z|x)} \left[ \log \frac{p(x,z)}{q(z|x)} \right] + KL(q(z|x)||p(z|x)) \\ &amp; \ge \mathbb{E}_{q(z|x)} \left[ \log \frac{p(x,z)}{q(z|x)} \right] \end{split}\]</span> ELBO指这个模型能够优化到什么程度，反映了我们对模型估计好坏程度。因为倒数第二行右边的KL散度是非负的，因此可以得到似然函数的一个下届，而这个边际似然也被称为模型证据。</p></blockquote><h2 id="分布的近似">3.2 分布的近似</h2><p>将公式（8）进行变形可以得到VAE的损失函数 <span class="math display">\[\mathcal{L} = \mathbb{E}_{X \sim P(X)} \left[ KL(P(z|X)||Q(z)) - \mathbb{E}_{X \sim P(z|X)} [\ln Q(X|z)] \right] \tag{9}\]</span> 最大化（8）式相当于最小化式（9）。</p><p>现在 <span class="math inline">\(Q(z), Q(X|z), P(z|X)\)</span> 三个分布式未知的。为了便于采样，假设 <span class="math inline">\(z\sim\mathcal{N}(0,I)\)</span>，也就是解决了 <span class="math inline">\(Q(z)\)</span>。<span class="math inline">\(P(z|X)\)</span> 是服从 <span class="math inline">\(\mathcal{N}(\mu, \sigma^2)\)</span>的正态分布，且均值和方差是通过神经网络拟合出来的。因此，式（9）中的KL散度可以表示为式（6）。</p><p>现在只剩下了生成部分 <span class="math inline">\(Q(X|z)\)</span>，如何选择分布？VAE原文中给出了两种候选方案：伯努利分布或正态分布。伯努利分布适用于X式多元二值向量的情况，例如X是0-1表示的黑白图像。这时我们使用神经网络 <span class="math inline">\(\phi(z)\)</span> 来拟合，从而得到 <span class="math display">\[Q(X|z) = \prod_{j=1}^d \left( \phi_{(j)}(z) \right)^{X_{(j)}} \left( 1 - \phi_{(j)}(z) \right)^{1 - X_{(j)}} \tag{10}\]</span> 这样就可以计算得到 <span class="math display">\[-\ln Q(X|z) = - \prod_{j=1}^d \left[ X_{(j)} \ln \phi_{(j)}(z) + (1 - X_{(j)}) \ln (1 - \phi_{(j)}(z)) \right] \tag{11}\]</span></p><p>正态分布情况下 <span class="math display">\[Q(X|z) = \frac{1}{\prod_{j=1}^d \sqrt{2 \pi \tilde{\sigma}^2_{(j)}(z)}} \exp \left( -\frac{1}{2} \left|\left| \frac{X-\tilde{\mu}}{\tilde{\sigma}(z)} \right|\right|^2\right) \tag{12}\]</span> 这里的 <span class="math inline">\(\tilde{\mu}(z),\tilde{\sigma}^2(z)\)</span> 是输入为 <span class="math inline">\(z\)</span>, 输出分别为均值和方差的神经网络，这里我们可以得到 <span class="math display">\[-\ln Q(X|z) = \frac{1}{2} \left|\left| \frac{X-\tilde{\mu}}{\tilde{\sigma}(z)} \right|\right|^2 + \frac{D}{2}\ln 2\pi + \frac{1}{2} \sum_{j=1}^d \ln \tilde{\sigma}^2_{(j)}(z) \tag{13}\]</span> 很多时候我们可以固定方差为一个常数，因此公式（13）可以简化为 <span class="math display">\[-\ln Q(X|z) \sim \frac{1}{2 \tilde{\sigma}^2} ||X - \tilde{\mu}(z)||^2 \tag{14} \]</span></p><p>因此，我们可以得出如下结论：对于二值数据，可以令 <span class="math inline">\(Q(X|z)\)</span> 服从伯努利分布，使用交叉熵作为损失函数；对于一般数据吗，我们令 <span class="math inline">\(Q(X|z)\)</span> 为固定方差的正态分布，并使用MSE作为损失函数。</p><h1 id="vae-的代码">4. VAE 的代码</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><code class="hljs python"><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">VAE</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, encoder, decoder, embed_size=<span class="hljs-number">10</span>, hidden_size = <span class="hljs-number">32</span></span>):<br>        <span class="hljs-built_in">super</span>(VAE, self).__init__()<br><br>        self.encoder = encoder<br>        self.decoder = decoder<br><br>        self.h2mu = nn.Linear(hidden_size, embed_size)<br>        self.h2logvar = nn.Linear(hidden_size, embed_size)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">reparameterize</span>(<span class="hljs-params">self, mu, logvar, deterministic = <span class="hljs-literal">False</span></span>):<br>        <span class="hljs-comment"># 个人认为这里也可以不用加 0.5， </span><br>        <span class="hljs-comment"># 因为本文中拟合的是 logvar 而不是 logvar 的平方，因此加了0.5</span><br>        std = torch.exp(<span class="hljs-number">0.5</span> * logvar) <br>        eps = torch.rand_like(std)<br>        z = mu + (std * eps <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> deterministic <span class="hljs-keyword">else</span> <span class="hljs-number">0</span>)<br>        <span class="hljs-keyword">return</span> z<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, <span class="hljs-built_in">input</span>, deterministic=<span class="hljs-literal">False</span></span>):<br>        h = self.encoder(<span class="hljs-built_in">input</span>)<br>        mu = self.h2mu(h)             <span class="hljs-comment"># 得到均值</span><br>        logvar = self.h2logvar(h)     <span class="hljs-comment"># 得到log(方差)</span><br><br>        z = self.reparameterize(mu, logvar, deterministic)   <span class="hljs-comment"># 根据均值和方差重构数据</span><br><br>        recon_param = self.decoder(z)<br>        <span class="hljs-keyword">return</span> recon_param, mu, logvar<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">kld_loss</span>(<span class="hljs-params">mu, logvar</span>):<br>    KLD = - <span class="hljs-number">0.5</span> * torch.<span class="hljs-built_in">sum</span>(<span class="hljs-number">1</span> + logvar - mu.<span class="hljs-built_in">pow</span>(<span class="hljs-number">2</span>) -<br>                            logvar.exp()) / mu.shape[<span class="hljs-number">0</span>]<br>    <span class="hljs-keyword">return</span> KLD<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">ce_loss</span>(<span class="hljs-params">recon_param, <span class="hljs-built_in">input</span></span>):<br>    CE = F.cross_entropy(recon_param, <span class="hljs-built_in">input</span>, reduction=<span class="hljs-string">&quot;sum&quot;</span>) / <span class="hljs-built_in">input</span>.shape[<span class="hljs-number">0</span>]<br>    <span class="hljs-keyword">return</span> CE<br>    <br><br></code></pre></td></tr></table></figure><h1 id="条件vae">5. 条件VAE</h1><p>条件VAE也称之为 Conditional VAE，也叫做CVAE。假定我们要建模的变量为 <span class="math inline">\(X\)</span>， 条件是 <span class="math inline">\(Y\)</span>， 隐变量 <span class="math inline">\(z\)</span> 的近似分布 <span class="math inline">\(Q(z|X,Y)\)</span> 和真实后验概率 <span class="math inline">\(P(z|X,Y)\)</span>。 在前面的讨论中，我们希望 <span class="math inline">\(X\)</span> 经过编码后，<span class="math inline">\(z\)</span> 的分布都具有零均值和单位方差，这个“希望”是通过加入了KL loss来实现的。如果现在多了类别信息 <span class="math inline">\(Y\)</span>。我们可以希望同一个类的样本都有一个专属的均值 <span class="math inline">\(\mu^Y\)</span>（方差不变，还是单位方差），这个 <span class="math inline">\(\mu^Y\)</span> 让模型自己训练出来。这样的话，有多少个类就有多少个正态分布，而在生成的时候，我们就可以通过控制均值来控制生成图像的类别。</p><figure><img src="/2023/02/28/VariationalInference/CVAE.png" alt="图3 CVAE的架构"><figcaption aria-hidden="true">图3 CVAE的架构</figcaption></figure><h1 id="参考">参考</h1><ol type="1"><li><a href="http://arxiv.org/abs/1312.6114">Diederik P. Kingma and Max Welling, Auto-Encoding Variational Bayes, ICLR 2014</a></li><li><a href="https://kexue.fm/archives/5253">苏剑林，变分自编码器系列，科学空间</a></li><li><a href="https://zhuanlan.zhihu.com/p/543706229">VAE模型+附加代码详解 - HiFuture的文章 - 知乎</a></li></ol>]]></content>
    
    
    <categories>
      
      <category>生成模型</category>
      
      <category>变分推断</category>
      
    </categories>
    
    
    <tags>
      
      <tag>近似定理</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>蒙特卡罗采样</title>
    <link href="/2022/11/20/MCMC/"/>
    <url>/2022/11/20/MCMC/</url>
    
    <content type="html"><![CDATA[<h1 id="背景知识">1. 背景知识</h1><h2 id="采样的动机">1.1 采样的动机</h2><ol type="1"><li>采样本身就是常见的任务，例如从生成模型 <span class="math inline">\(P(\mathbf{x})\)</span> 中采样出样本。</li><li>求积分或者复杂求和。例如，求 <span class="math inline">\(\int p(\mathbf{x})f(\mathbf{x})dx\)</span> 可以转化为 <span class="math inline">\(\mathbb{E}_{x \sim p(\mathbf{x})} \left[f(\mathbf{x})\right]\)</span>，从 <span class="math inline">\(p(\mathbf{x})\)</span> 中采样出 <span class="math inline">\(N\)</span> 个样本，求解 <span class="math inline">\(\frac{1}{N}\sum_{i=1}^N f(\mathbf{x}^{i})\)</span></li></ol><blockquote><p>根据李航老师的《统计学习方法》，假设多元随机变量 <span class="math inline">\(\mathbf{x}\in\mathcal{X}\)</span>， 其概率密度函数为 <span class="math inline">\(p(\mathbf{x})\)</span>， <span class="math inline">\(f(\mathbf{x})\)</span> 为定义在 <span class="math inline">\(\mathbf{x}\in\mathcal{X}\)</span> 上的函数，采样的目标是获得概率分布为 <span class="math inline">\(p(\mathbf{x})\)</span> 的样本集合，以及求函数 <span class="math inline">\(f(\mathbf{x})\)</span> 的数学期望 <span class="math inline">\(\mathbb{E}_{p(\mathbf{x})}[f(\mathbf{x})]\)</span>。</p></blockquote><h2 id="如何衡量采样的质量什么是好的样本">1.2 如何衡量采样的质量？（什么是好的样本？）</h2><ol type="1"><li>样本趋向于高概率区域，同时兼顾其他区域。以高斯分布为例，我们希望绝大多数样本位于 <span class="math inline">\(3\sigma\)</span> 之间。</li><li>样本之间要相互独立的，即相关性不强。</li></ol><p>以选举为例，我们希望按照人数比例选举代表。例如绝大多数是工人和农民，我们希望绝大多数代表是工人和农民（性质1）；而且这些代表应该是不同工厂和农场的，不是同一家工厂或同一个家族的（性质2）。</p><h2 id="采样是困难的">1.3 采样是困难的</h2><ol type="1"><li>配分函数是不可解的。即 <span class="math inline">\(p(\mathbf{x}) = \frac{\hat{p}(\mathbf{x})}{Z} = \frac{\hat{p}(\mathbf{x})}{\int \hat{p}(\mathbf{x}) d \mathbf{x}}\)</span></li><li>高维环境下，状态空间过于复杂，无法通过遍历的方式覆盖所有状态空间。直接采样不可行。</li></ol><h1 id="一些采样方法介绍">2. 一些采样方法介绍</h1><p>回想推断问题，推断问题可以分为以下几种：</p><ul><li>精确推断</li><li>近似推断<ul><li>确定性近似 （变分推断）</li><li>随机近似 （MCMC）</li></ul></li></ul><p>例如观测数据 <span class="math inline">\(X\)</span> 是根据隐变量 <span class="math inline">\(Z\)</span> 生成的，我们希望根据观测变量推断隐变量的分布 <span class="math inline">\(P(Z|X)\)</span> 并求解 <span class="math inline">\(\mathbb{E}_{\mathbf{z}}\left[f(\mathbf{z})\right]\)</span>。通常我们可以通过积分的方式来实现： <span class="math display">\[\mathbb{E}_{\mathbf{z}\sim p(\mathbf{z}|\mathbf{x})}[f(\mathbf{z})] = \int p(\mathbf{z}|\mathbf{x})f(\mathbf{z}) d \mathbf{z} \tag{1}\]</span> 通过从分布 <span class="math inline">\(p(\mathbf{z}|\mathbf{x})\)</span> 中采样 N个点，求解 <span class="math inline">\(\frac{1}{N} \sum_{i=1}^N f(\mathbf{z}^{(i)})\)</span>。所以问题就转化成如何从分布中采样出N个样本。</p><h2 id="概率分布采样">2.1 概率分布采样</h2><p>对于概率分布函数 <span class="math inline">\(p(\mathbf{z})\)</span> （PDF），可以计算其CDF，其CDF属于[0,1]上的均匀分布，可以从[0,1]中采样N个点，并根据CDF的逆计算这N个点对应的输入值 <span class="math inline">\(\mathbf{z}\)</span>。</p><p>这种方法的缺陷在于CDF难以求解，适用情况少。</p><h2 id="接受-拒绝采样">2.2 接受-拒绝采样</h2><figure><img src="/2022/11/20/MCMC/AccRejSamp.png" alt="图1 接受拒绝采样"><figcaption aria-hidden="true">图1 接受拒绝采样</figcaption></figure><p>接受-拒绝采样的核心思想是对于难以直接采样的分布 <span class="math inline">\(p(\mathbf{z})\)</span>， 构造易于采样的 proposal distribution （建议分布） <span class="math inline">\(q(\mathbf{z})\)</span>，使得 <span class="math inline">\(kq(\mathbf{z})\)</span> 处处不小于 <span class="math inline">\(p(\mathbf{z})\)</span>。采样时，如果采到的样本位于灰色阴影区域，就拒绝，否则接受。我们可以定义接受率 <span class="math inline">\(\alpha=\frac{p(\mathbf{z}^{(i)})}{kq(\mathbf{z}^{(i)})}\)</span>，接受率 <span class="math inline">\(\alpha \in [0,1]\)</span>。</p><p>具体采样步骤如下：</p><p>1). 从分布<span class="math inline">\(q\)</span>中采样出样本 <span class="math inline">\(\mathbf{z}^{(i)}\)</span> 2). 从均匀分布 <span class="math inline">\(U(0,1)\)</span> 中采样 <span class="math inline">\(u_i\)</span> 3). 如果 <span class="math inline">\(u_i \le \alpha\)</span> 接受样本，否则拒绝</p><p>我们可以看出，建议分布 <span class="math inline">\(q\)</span> 越接近 <span class="math inline">\(p\)</span>， 接受率越高。该方法存在的主要问题在于一是合适的q(x)分布比较难以找到，二是很难确定一个合理的 k 值。这两个问题会导致拒绝率很高，无用计算增加。</p><h2 id="重要性采样">2.3 重要性采样</h2><p>重要性采样不是从概率分布中采样，而是从期望中采样。根据公式（1），我们可以做如下变换： <span class="math display">\[\begin{split}\mathbb{E}_{p(\mathbf{z})} [f(\mathbf{z})] &amp;= \int p(\mathbf{z}) f(\mathbf{z}) d \mathbf{z} \\&amp;= \int \frac{p(\mathbf{z})}{q(\mathbf{z})} q(\mathbf{z}) f(\mathbf{z}) d \mathbf{z} \\&amp;= \int f(\mathbf{z}) \frac{p(\mathbf{z})}{q(\mathbf{z})} q(\mathbf{z}) d\mathbf{z} \\&amp; \approx \frac{1}{N} \sum_{i=1}^N f(\mathbf{z}^{(i)})\frac{p(\mathbf{z}^{(i)})}{q(\mathbf{z}^{(i)})}\end{split}\tag{2}\]</span> 重要性体现在系数 <span class="math inline">\(\frac{p(\mathbf{z}^{(i)})}{q(\mathbf{z}^{(i)})}\)</span> 上，标明二者的分布越接近，权重越大。</p><h3 id="sampling-importance-resampling">2.3.1 Sampling-Importance-Resampling</h3><p>由于直接使用重要性采样效率也可能很低。因此可以将系数 <span class="math inline">\(\frac{p(\mathbf{z}^{(i)})}{q(\mathbf{z}^{(i)})}\)</span> 看作权重，对采出来的样本进行重采样。简单理解就是，权重越大，样本重复次数越多。</p><h1 id="马尔可夫链">3. 马尔可夫链</h1><h2 id="基本定义">3.1 基本定义</h2><p>假设在时刻0的随机变量 <span class="math inline">\(\mathbf{x}_0\)</span> 遵循概率分布 <span class="math inline">\(P(\mathbf{x}_0)=\pi_0\)</span>，称为初始状态分布，在某个时刻 <span class="math inline">\(t \ge 1\)</span> 的随机变量 <span class="math inline">\(\mathbf{x}_t\)</span> 与前一个时刻的随机变量 <span class="math inline">\(\mathbf{x}_{t-1}\)</span> 之间有条件分布 <span class="math inline">\(P(\mathbf{x}_t |\mathbf{x}_{t-1})\)</span>， 如果 <span class="math inline">\(\mathbf{x}_t\)</span> 只依赖于 <span class="math inline">\(\mathbf{x}_{t-1}\)</span>， 而不依赖于过去的随机变量 <span class="math inline">\(\{\mathbf{x}_0, \mathbf{x}_1, \ldots, \mathbf{x}_{t-2}\}\)</span>，这一性质称为马尔可夫性，即：</p><p><span class="math display">\[P(\mathbf{x}_t|\mathbf{x}_0, \mathbf{x}_1, \cdots, \mathbf{x}_{t-1}) = P(\mathbf{x}_t |\mathbf{x}_{t-1}) \quad t=1,2,\cdots \tag{3}\]</span></p><p>具有马尔可夫性的随机序列 <span class="math inline">\(\mathbf{X} = \{\mathbf{x}_0,\mathbf{x}_1, \cdots, \mathbf{x}_{t}, \cdots\}\)</span> 称为马尔可夫链（Markov Chain）或者马尔可夫过程（Markov Process）。</p><p>马尔可夫性的直观解释是“未来只依赖于现在（假设现在已知），而与过去无关”。</p><h2 id="离散状态马尔可夫链">3.2 离散状态马尔可夫链</h2><h3 id="转移概率矩阵和状态分布">3.2.1 转移概率矩阵和状态分布</h3><p>离散状态马尔可夫链 <span class="math inline">\(\mathbf{X} = \{\mathbf{x}_0,\mathbf{x}_1, \cdots, \mathbf{x}_{t}, \cdots\}\)</span>， 随机变量 <span class="math inline">\(\mathbf{x}_t (t=0,1,2,\cdots)\)</span> 定义在离散空间 <span class="math inline">\(\mathcal{S}\)</span>，转移概率分布可以用矩阵表示。如果马尔可夫链在时刻 <span class="math inline">\((t-1)\)</span> 处于状态 <span class="math inline">\(i\)</span>, 在 <span class="math inline">\(t\)</span> 时刻移动到状态 <span class="math inline">\(j\)</span>， 则转移概率记作： <span class="math display">\[p_{ij} = (\mathbf{x}_t = j | \mathbf{x}_{t-1} = i), \quad i=1,2,\cdots; \quad j=1,2,\cdots \tag{4}\]</span> 满足 <span class="math display">\[p_{ij}\ge0, \sum_j p_{ij} = 1\]</span> 转移概率矩阵可以写为： <span class="math display">\[\boldsymbol{P} = \left[\begin{matrix}p_{11} &amp; p_{12} &amp; p_{13} &amp; \cdots \\p_{21} &amp; p_{22} &amp; p_{23} &amp; \cdots \\p_{31} &amp; p_{32} &amp; p_{33} &amp; \cdots \\\cdots &amp; \cdots &amp; \cdots &amp; \cdots \\\end{matrix}\right] \tag{5}\]</span></p><p>转移概率矩阵 <span class="math inline">\(\boldsymbol{P}\)</span> 满足公式（2）性质，且满足这两个条件的矩阵通常被称为随机矩阵（Stochastic Matrix）。注意，这里矩阵行之和为1，表示从状态 <span class="math inline">\(i\)</span> 转换至状态空间 <span class="math inline">\(\mathcal{S}\)</span> 中任意状态的概率之和为1.</p><p>将马尔可夫链在 <span class="math inline">\(t\)</span> 时刻的概率分布称为 <span class="math inline">\(t\)</span> 时刻的状态分布，记作： <span class="math display">\[\pi(t)=\left[\begin{matrix}\pi_1(t)\\\pi_2(t)\\\vdots\end{matrix}\right] \tag{6}\]</span> 其中 <span class="math inline">\(\pi_i(t)\)</span> 表示时刻 <span class="math inline">\(t\)</span> 状态为 <span class="math inline">\(i\)</span> 的概率 <span class="math inline">\(P(\mathbf{x}_t = i)\)</span>， <span class="math display">\[\pi_i(t) = P(\mathbf{x}_t = i) \quad i=1,2,\cdots \tag{7}\]</span> 这里 <span class="math inline">\(\sum_i \pi_i(t) = 1\)</span>。特别地，马尔可夫链的初始状态分布可以表示为 <span class="math display">\[\pi(0)=\left[\begin{matrix}\pi_1(0)\\\pi_2(0)\\\vdots\end{matrix}\right] \tag{8}\]</span></p><p>马尔可夫链 <span class="math inline">\(X\)</span> 在 <span class="math inline">\(t\)</span> 时刻的状态分布，可以由 <span class="math inline">\((t-1)\)</span> 时刻的状态分布及转移概率分布决定： <span class="math display">\[\pi(t) = P\pi(t-1) \tag{9}\]</span> 这是因为 <span class="math display">\[\begin{split}\pi_i(t) &amp;= P(\mathbf{x}_t = i) \\&amp;= \sum_{m\in \mathcal{S}} P(\mathbf{x}_t = i|\mathbf{x}_{t-1}=m) P(\mathbf{x}_{t-1} = m) \\&amp;= \sum_{m\in\mathcal{S}} p_{mi} \pi_m(t-1) \end{split}\tag{10}\]</span></p><p>马尔可夫链在 <span class="math inline">\(t\)</span> 时刻的状态分布可以通过递推得到，根据公式（7），我们可以得到 <span class="math display">\[\pi(t)=\boldsymbol{P} \pi(t-1)=\boldsymbol{P} (\boldsymbol{P} \pi(t-2))=\boldsymbol{P} ^2\pi(t-2)=\cdots=\boldsymbol{P} ^t\pi(0) \tag{11}\]</span> 其中 <span class="math inline">\(P^t\)</span> 称为 <span class="math inline">\(t\)</span> 步转移概率矩阵， <span class="math display">\[p_{ij}^t = P(\mathbf{x}_t=j|\mathbf{x}_0=i)\tag{12}\]</span> 表示时刻0从状态 <span class="math inline">\(i\)</span> 触发，时刻 <span class="math inline">\(t\)</span> 到达状态 <span class="math inline">\(j\)</span> 的 <span class="math inline">\(t\)</span> 步转移概率。</p><p>尤其是，当t=0时，做如下规定： <span class="math display">\[p_{ij}^0 = \begin{cases}0, \quad &amp; i \neq j\\1, \quad &amp; i = j\end{cases}\tag{13}\]</span> 我们可以认为初始状态下，节点状态保持不变，不会发生状态转移。</p><h3 id="champman-kolmogorov-方程简称ck方程">3.2.2 Champman-Kolmogorov 方程，简称CK方程</h3><p>CK方程旨在描述 <span class="math inline">\(p_{ij}^t\)</span> 和 <span class="math inline">\(p_{ij}\)</span> 之间的关系，对于一切 <span class="math inline">\(t,n \ge 0, i,j \in \mathcal{S}\)</span>，有以下二式成立：</p><ul><li><span class="math display">\[p_{ij}^{t+n} = \sum_{k\in\mathcal{S}} p_{ik}^t p_{kj}^n \tag{14}\]</span></li><li><span class="math display">\[\boldsymbol{P}^t = \boldsymbol{P} \cdot \boldsymbol{P}^{t-1} \tag{15} \]</span></li></ul><h2 id="马尔可夫链的性质">3.3 马尔可夫链的性质</h2><figure><img src="/2022/11/20/MCMC/StateClass.png" alt="图2 马尔可夫链状态集合"><figcaption aria-hidden="true">图2 马尔可夫链状态集合</figcaption></figure><blockquote><p><strong>前言</strong> 马尔可夫链的性质是与马尔可夫链的状态划分密切相关的，所有状态如图1所示，通俗解读如下：</p><ul><li>非常返： 不确定事情不一定会发生，例如买彩票中特等奖</li><li>常返：事情一定会发生，例如抛硬币早晚会抛到正面</li><li>正常返：事情经过有限步会发生</li><li>零常返：事情要经过无穷步才会发生，例如取到标准正态分布的一个点</li><li>周期的：在马尔可夫链中，从该状态触发，再返回该状态时时间间隔为 <span class="math inline">\(d \ge 2\)</span>（注意，这里不一定是完整的周期）</li><li>非周期：周期为1</li><li>遍历态： 不可约，非周期，且正常返</li></ul></blockquote><h3 id="可约连通不可约">3.3.1 可约（连通）/不可约</h3><p><span class="math inline">\(\color{green}{\textbf{定义 1 }}\)</span>如果存在 <span class="math inline">\(n \ge 0\)</span>，使得 <span class="math inline">\(p_{ij}^{(n)}&gt;0\)</span>，记为 <span class="math inline">\(i \rightarrow j\)</span>，称为状态 <span class="math inline">\(i\)</span> 可达状态 <span class="math inline">\(j\)</span>（<span class="math inline">\(i,j\in\mathcal{S}\)</span>）。如果同时有 <span class="math inline">\(j \rightarrow i\)</span>，则称状态 <span class="math inline">\(j\)</span> 与 <span class="math inline">\(i\)</span> 互通，记为 $ j i$。</p><p><span class="math inline">\(\color{red}{\textbf{定理 1 }}\)</span> 互通是一种等价关系，即满足以下三个性质：</p><ul><li><p>自返性： <span class="math inline">\(i \leftrightarrow i\)</span></p></li><li><p>对称性： <span class="math inline">\(j \leftrightarrow i\)</span> 则 <span class="math inline">\(i \leftrightarrow j\)</span></p></li><li><p>传递性： <span class="math inline">\(k \leftrightarrow j, j \leftrightarrow i\)</span>，则 <span class="math inline">\(k\leftrightarrow i\)</span></p></li></ul><p><span class="math inline">\(\color{green}{\textbf{定义 2 }}\)</span> 我们把任何两个互通状态归为一类，由上述定理可知，同在一类的状态应该都是互通的，并且任何一个状态不能同属于两个不同的类。<strong>如果Markov链只存在一个类，就称它是不可约的（irreducible），否则称为可约的（reducible）。</strong></p><h3 id="周期非周期">3.3.2 周期/非周期</h3><p><span class="math inline">\(\color{green}{\textbf{定义 3 }}\)</span> 如果集合 <span class="math inline">\(\{n: n\ge 1, p_{ii}^{(n)}&gt;0\}\)</span> 非空，则称它的最大公约数 <span class="math inline">\(d=d(i)\)</span> 为 <span class="math inline">\(i\)</span> 的周期。<strong>如果 <span class="math inline">\(d&gt;i\)</span>，则称 <span class="math inline">\(i\)</span> 是周期的（periodic）；如果 <span class="math inline">\(d=1\)</span>， 则称 <span class="math inline">\(i\)</span> 是非周期的（aperiodic）</strong>。并且特别规定，当上述集合为空集时，<span class="math inline">\(i\)</span> 的周期无穷大。</p><p>对于一个马尔可夫链 <span class="math inline">\(X\)</span> 来说，若所有状态的周期均为1，称该链是非周期的，否则是周期的。</p><p><span class="math inline">\(\color{red}{\textbf{定理 2 }}\)</span> 如果状态 <span class="math inline">\(j,i\)</span>同属一类，则 <span class="math inline">\(d(i)=d(j)\)</span>。</p><p><span class="math inline">\(\textbf{证明} \quad\)</span> 由类的定义可知 <span class="math inline">\(i \leftrightarrow j\)</span>，即存在 <span class="math inline">\(m,n \ge 0\)</span>，使得 <span class="math inline">\(p_{ij}^{(m)} &gt; 0, p_{ji}^{(n)}&gt;0\)</span>，则 <span class="math inline">\(p_{ii}^{(n+m)} = \sum_{k\in\mathcal{S}} p_{ik}^{(m)} p_{ki}^{(n)} \ge p_{ij}^{(m)} p_{ji}^{(n)} &gt;0\)</span>。对于所有 <span class="math inline">\(p_{jj}^{(s)} &gt;0\)</span>的 <span class="math inline">\(s\)</span>，有 <span class="math inline">\(p_{ii}^{(m+s+n)} \ge p_{ij}^{(m)} p_{jj}^{(s)} p_{ji}^{(n)} &gt;0\)</span>。显然 <span class="math inline">\(d(i)\)</span> 应该同时整除 <span class="math inline">\(m+n\)</span> 和 <span class="math inline">\(m+s+n\)</span>，则它必定整除 <span class="math inline">\(s\)</span>。而 <span class="math inline">\(d(j)\)</span>是 <span class="math inline">\(j\)</span> 的周期，所以 <span class="math inline">\(d(i)\)</span>必定整除 <span class="math inline">\(d(j)\)</span>。反过来亦可证 <span class="math inline">\(d(j)\)</span> 整除 <span class="math inline">\(d(i)\)</span>，于是 <span class="math inline">\(d(i) = d(j)\)</span>。</p><h3 id="常返recurrent非常返transient">3.3.3 常返（Recurrent）/非常返（Transient）</h3><p><span class="math inline">\(\color{green}{\textbf{定义 4 }}\)</span> 对于任何状态<span class="math inline">\(i,j\)</span>，以 <span class="math inline">\(f_{ij}^{(n)}\)</span> 记录从 <span class="math inline">\(i\)</span> 出发经过 <span class="math inline">\(n\)</span> 步后首次到达 <span class="math inline">\(j\)</span> 的概率。令 <span class="math inline">\(f_{ij} = \sum_{n=1}^{\infty}f_{ij}^{(n)}\)</span>，如果 <span class="math inline">\(f_{jj}=1\)</span>，则称状态 <span class="math inline">\(j\)</span>为常返状态；若 <span class="math inline">\(f_{jj}&lt;1\)</span>，则称状态 <span class="math inline">\(j\)</span> 为非常返状态或瞬过状态。</p><blockquote><p>常返与否可以理解为从 <span class="math inline">\(j\)</span> 出发未来某个时刻是否一定能回到 <span class="math inline">\(j\)</span>。</p></blockquote><h3 id="正常返positive-recurrent零常返null-recurrent">3.3.4 正常返（Positive Recurrent）/零常返（Null Recurrent）</h3><p>对于常返的状态 <span class="math inline">\(j\)</span>，定义 <span class="math display">\[\mu_i = \sum_{n=1}^{\infty} n f_{ii}^{(n)} \tag{16}\]</span> 为从状态 <span class="math inline">\(i\)</span> 出发返回状态 <span class="math inline">\(i\)</span> 所需的平均步数。</p><p><span class="math inline">\(\color{green}{\textbf{定义 5 }}\)</span> 对于常返状态 <span class="math inline">\(i\)</span>， 如果 <span class="math inline">\(\mu_i &lt; +\infty\)</span>，则称 <span class="math inline">\(i\)</span> 为正常返（positive recurrent）状态；若 <span class="math inline">\(\mu_i = + \infty\)</span>，则称 <span class="math inline">\(i\)</span> 为零常返状态。</p><figure><img src="/2022/11/20/MCMC/PosRecurrent.png" alt="图2 正常返与零常返举例"><figcaption aria-hidden="true">图2 正常返与零常返举例</figcaption></figure><p>举例： 根据级数的发散思维，如果 <span class="math inline">\(p=\frac{1}{2}\)</span> 时， <span class="math inline">\(f_{11}^{(2)} = \frac{1}{2}, f_{11}^{(4)} = \frac{1}{2^2}, f_{11}^{(8)} = \frac{1}{2^3}, \cdots\)</span>，其余为0，所以 <span class="math display">\[f_{11} = 0+\frac{1}{2} + 0+ \frac{1}{2^2} + 0 + 0 +0 + \frac{1}{2^3} + \cdots = 1\]</span> <span class="math display">\[\mu_1 = 0 + \frac{2}{2} + 0 + \frac{4}{2^2} + 0+ 0+ 0+ \frac{8}{2^3} + \cdots = \infty\]</span> 因此是零常返。如果令 <span class="math inline">\(p=\frac{1}{4}\)</span>，<span class="math inline">\(f_{11}^{(2)} = \frac{3}{4}, f_{11}^{(4)} = \frac{3}{4^2}, f_{11}^{(8)} = \frac{3}{4^3}, \cdots\)</span>，其余为0，所以 <span class="math display">\[f_{11} = 0+\frac{3}{4} + 0+ \frac{3}{4^2} + 0 + 0 +0 + \frac{3}{4^3} + \cdots = 1\]</span> <span class="math display">\[\mu_1 = 3\times ( 0 + \frac{2}{4} + 0 + \frac{4}{4^2} + 0+ 0+ 0+ \frac{8}{4^3} + \cdots) = 3\]</span></p><p>，因此是正常返的。<strong>本质原因还是因为返回的概率增大了。</strong></p><h3 id="关于上述状态之间的关系">3.3.5 关于上述状态之间的关系</h3><p><span class="math inline">\(\color{blue}{\textbf{引理 1 }}\)</span> 对于任意状态 <span class="math inline">\(i,j, 1\le n &lt; +\infty\)</span> 有 <span class="math display">\[ f_{ij}^{(n)} = \sum_{k\neq j \land k \in \mathcal{S}} f_{ik}^{(1)}f_{kj}^{(n-1)} \tag{17}\]</span></p><p><span class="math inline">\(\textbf{证明}\quad\)</span> 当 <span class="math inline">\(n=1\)</span> 时，显然有 <span class="math inline">\(f_{ij}^{(1)} = p_{ij}\)</span>，下面考虑 <span class="math inline">\(n&gt;1\)</span>的情况。令 <span class="math inline">\(T_{ij}\)</span>表示从状态 <span class="math inline">\(i\)</span>出发，首次到达状态 <span class="math inline">\(j\)</span>的时间。由于 <span class="math display">\[ \{T_{ij}=n, X_0=i\} =\cup_{k\neq j} \{ X_0=i, X_1 =k, X_l \neq j, 2\le l \le n-1, X_n=j \}\]</span> 因此有 <span class="math display">\[\begin{split}P(T_{ij}=n|X_0=i) &amp;= \sum_{k\neq j} P(X_1 = k|X_0=i) \times \\&amp;P(X_n=j|X_1=k, X_0=i, X_l\neq j, 2\le l\le n-1)\end{split}\]</span> 由马尔科夫定义，我们可以得到 <span class="math display">\[f_{ij}^{(n)}=\sum_{k\neq j} p_{ik}f_{kj}^{(n-1)}=\sum_{k\neq j}f_{ij}^{(1)}f_{ij}^{(n-1)}  \]</span></p><p><span class="math inline">\(\color{blue}{\textbf{引理 2 }}\)</span> 对于任意状态 <span class="math inline">\(i,j, 1 \le n \le + \infty\)</span>，有 <span class="math display">\[ p_{ij}^{(n)} = \sum_{l=1}^n f_{ij}^{(l)} p_{jj}^{(n-l)} \tag{18}\]</span></p><p><span class="math inline">\(\textbf{证明}\quad\)</span> 根据首次进入法，注意到 <span class="math inline">\(X_n=j\)</span> 时 <span class="math inline">\(T_{ij} \le n\)</span>， <span class="math display">\[\begin{split}P_{ij}^{(n)} &amp;= P(X_0=i, X_n=j) = \sum_{l=1}^n P(X_0=i, X_n=j, T_{ij}=l) \\&amp;= \sum_{l=1}^n P(X_0=i, X_n=j, X_l=j, X_k\neq j,0&lt;k&lt;l)\\&amp;= \sum_{l=1}^n P(X_0=i, X_l=j, X_k \neq j, 0&lt;k&lt;l)P(X_n=j|X_l=j)\\&amp;= \sum_{v=1}^n f_{ij}^{(l)}P_{jj}^{(n-l)}\end{split}\]</span></p><p>从状态 <span class="math inline">\(i\)</span> 出发经过 <span class="math inline">\(r\)</span> 步以概率 <span class="math inline">\(f_{ij}^{(r)}, r\le n\)</span> 首次到达状态 <span class="math inline">\(j\)</span> ，对于 <span class="math inline">\(1 \le r \le n\)</span> 剩下 <span class="math inline">\(n-r\)</span> 步再次到达状态 <span class="math inline">\(j\)</span> 的概率为 $ p_{ii}^{(n-r)} $。对于这些彼此不相容的概率求和，我们可以得到一个重要的关系式： <span class="math display">\[ p_{ij}^{(n)} = \sum_{r=1}^n f_{ij}^{r} p_{jj}^{(n-r)} \quad n\ge 1 \tag{19}\]</span> 其中 <span class="math display">\[f_{ij}^{(0)} = 0 \quad p_{jj}^{(0)}=1 \quad p_{ij}^{0}=0 \quad  f_{ij}^{(1)}=p_{ij} \quad i\neq j \tag{20}\]</span> 设 <span class="math inline">\(P_{ij}(z)\)</span>和 <span class="math inline">\(F_{ij}(z)\)</span>分别表示序列 <span class="math inline">\(\{p_{ij}^{(n)}\}\)</span> 和 <span class="math inline">\(\{f_{ij}^{(n)}\}\)</span> 的矩生成函数，那么我们可以得到下式 <span class="math display">\[\begin{split} P_{ij}(z) &amp;= \sum_{n=0}^\infty p_{ij}^{(n)} z^n = p_{ij}^{(0)} + \sum_{n=1}^\infty \sum_{r=1}^n f_{ij}^{(r)} p_{jj}^{(n-r)} z^n \\&amp;= p_{ij}^{(0)} + \sum_{r=1}^\infty f_{ij}^{(r)}z^r \sum_{k=0}^\infty p_{jj}^{(k)} z^k = p_{ij}^{(0)} + F_{ij}(z)P_{jj}(z)\end{split}\tag{21}\]</span> 特别地，对于 <span class="math inline">\(i=j\)</span>， 我们得到有用的关系式 <span class="math display">\[P_{ii}(z) = 1+ F_{ii}(z)P_{ii}(z) \tag{22} \]</span> 或 <span class="math display">\[ P_{ii}(z) = \frac{1}{1-F_{ii}(z)} \tag{23}\]</span> 显然， <span class="math display">\[f_{ij} = \sum_{n=1}^\infty f_{ij}^{(n)} =F_{ij}(1) \tag{24} \]</span></p><p><span class="math inline">\(\color{blue}{\textbf{引理 3 }}\)</span> 状态 <span class="math inline">\(i\)</span> 是常返的，当且仅当 <span class="math display">\[\sum_{n=0}^\infty p_{ii}^{(n)} =\infty \tag{25}\]</span></p><p><span class="math inline">\(\textbf{证明}\quad\)</span> 根据定义，如果状态 <span class="math inline">\(i\)</span> 是常返的，那么 <span class="math display">\[f_{ii}=\sum_{n=1}^{\infty} f_{ii}^{(n)} = \lim\limits_{z\rightarrow 1} F_{ii}(z) = 1\]</span> 那么根据公式（23）可得 <span class="math display">\[ \sum_{n=1}^\infty p_{ii}^{(n)} = \lim\limits_{z\rightarrow 1} P_{ii}(z) = \lim\limits_{z\rightarrow 1} \frac{1}{1-F_{ii}(z)} = \infty \]</span></p><p><span class="math inline">\(\color{blue}{\textbf{引理 4 }}\)</span> 状态 <span class="math inline">\(i\)</span> 是非常返的，当且仅当 <span class="math display">\[\sum_{n=0}^\infty p_{ii}^{(n)} &lt;\infty \tag{26}\]</span> 若状态 <span class="math inline">\(j\)</span> 是非常返状态，对于所有的状态 <span class="math inline">\(i\)</span>， <span class="math display">\[\sum_{n=0}^\infty p_{ij}^{(n)} &lt; \infty \tag{27} \]</span></p><p><span class="math inline">\(\textbf{证明 }\quad\)</span> 假定 <span class="math display">\[\sum_{n=0}^\infty p_{ii}^{(n)}&lt;\infty \]</span> 由于 <span class="math inline">\(p_{ii}^{(n)}\)</span> 非负，当 <span class="math inline">\(z\rightarrow 1\)</span> 时，<span class="math inline">\(P_{ii}(z)\)</span> 单调递增，并且对每一个 <span class="math inline">\(N\)</span> <span class="math display">\[\sum_{n=0}^N p_{ii}^{(n)} \le \lim\limits_{z\rightarrow 1} P_{ii}(z) \le \sum_{n=0}^\infty p_{ii}^{(0)} \]</span> 因此，当$ N $, 取极限，我们可以得到 <span class="math display">\[\lim\limits_{z\rightarrow 1} P_{ii}^{(n)} = \sum_{n=0}^\infty p_{ii}^{(n)} \lt \infty  \]</span></p><p>对于公式（27），我们利用公式（19）证明： <span class="math display">\[ \sum_{n=0}^\infty p_{ij}^{(n)} = \sum_{n=0}^\infty \sum_{r=0}^n f_{ij}^{(r)} p_{jj}^{(n-r)} = \sum_{m=0}^\infty p_{jj}^{(m)} \sum_{r=0}^\infty f_{ij}^{(r)} \le \sum_{m=0}^\infty p_{jj}^{(m)} \lt \infty \]</span></p><p><span class="math inline">\(\color{blue}{\textbf{引理 5 }}\)</span> 当且仅当 <span class="math display">\[ \sum_{n=0}^\infty p_{jj}^{(n)} = \infty \quad \text{并且当} n\rightarrow \infty \text{时，} p_{jj}^{(n)} \rightarrow 0 \tag{28}\]</span> 状态 <span class="math inline">\(j\)</span> 是零常返的，在这种情况下，对所有的 <span class="math inline">\(i\)</span>， <span class="math display">\[\text{当}n\rightarrow \infty \text{时} \quad p_{ij}^{(n)} \rightarrow 0 \tag{29}\]</span></p><p><span class="math inline">\(\color{blue}{\textbf{引理 6 }}\)</span> 当且仅当 <span class="math inline">\(\mu_j \lt \infty\)</span> 非周期态 <span class="math inline">\(j\)</span> 是遍历的，在这种情况下： <span class="math display">\[\lim\limits_{n\rightarrow \infty} p_{ij}^{(n)} \rightarrow \frac{f_{ij}}{\mu_{ij}} \tag{30}\]</span></p><p><span class="math inline">\(\textbf{证明}\quad\)</span> 为证明引理5 和引理6， 我们定义 <span class="math display">\[v_n = p_{jj}^{(n)} -p_{jj}^{(n-1)} \quad n\ge 1 \quad, v_0 = p_{jj}^{(0)} \]</span> 所以， <span class="math display">\[ \sum_{k=0}^n v_k = p_{jj}^{(n)} \]</span> 定义 <span class="math display">\[ V(z) = \sum_{n=0}^\infty v_n z^n = P_{jj}(z) -zP_{jj}(z) = \frac{1-z}{1-F_{jj}(z)} \]</span> 于是 <span class="math display">\[\lim\limits_{z\rightarrow 1} V(z) = \lim\limits_{z\rightarrow 1} \frac{1}{(1-F_{jj}(z))/(1-z)}=\frac{1}{F_{jj}^{&#39;}(1)} = \frac{1}{\mu_j} \]</span> 且 <span class="math display">\[\lim\limits_{z\rightarrow 1} V(z) = \lim\limits_{z\rightarrow 1}\sum_{k=0}^\infty v_k z^k = \lim\limits_{n\rightarrow \infty} \sum_{k=0}^{n} v_k = \lim\limits_{n\rightarrow \infty} p_{jj}^{(n)} \]</span> 因此，我们可以得到 <span class="math display">\[\lim\limits_{n\rightarrow\infty} p_{jj}^{(n)} = \frac{1}{\mu_j}  \]</span> 引理5中公式（28）得证。</p><blockquote><p><strong>步骤解释1：</strong> <span class="math display">\[\begin{split} P_{jj}(z) - zP_{jj}(z) &amp;= \{p_{jj}^{(0)}z^0 + p_{jj}^{(1)}z^1 + p_{jj}^{(2)}z^2 + \cdots \} - \{ p_{jj}^{(0)}z^1 + p_{jj}^{(1)}z^2 + p_{jj}^{(2)}z^3 + \cdots \} \\&amp;= p_{jj}^{(0)}z^0 + (p_{jj}^{(1)}-p_{jj}^{(0)})z^1 + (p_{jj}^{(2)}-p_{jj}^{(1)})z^2 + \cdots \\&amp;= \sum_{n=0}^\infty v_n z^n\end{split}\]</span></p></blockquote><blockquote><p><strong>步骤解释2:</strong> 根据导数定义 <span class="math display">\[F^{&#39;}(1)=\lim\limits_{z\rightarrow 1^-} \frac{F_{jj}(1)-F_{jj}(z)}{1-z^-}\]</span></p></blockquote><p>接下来证明引理5中公式（29）。根据公式（19），我们可以得到 <span class="math display">\[\lim\limits_{n\rightarrow\infty} p_{ij}^{(n)} = \lim\limits_{n\rightarrow\infty}\sum_{k=1}^n f_{ij}^{(k)}p_{jj}^{(n-k)} = \sum_{k=1}^\infty \frac{f_{ij}^{(k)}}{\mu_j} = \frac{f_{ij}}{\mu_j}  \]</span> 如果 <span class="math inline">\(j\)</span> 是零常返状态，那么 <span class="math inline">\(\mu_j = \infty\)</span>，所以 <span class="math display">\[\lim\limits_{n\rightarrow\infty} p_{ij}^{(n)} \rightarrow 0 \]</span> 因此，引理5中公式（29）得证。</p><p>接下来证明引理6。如果状态 <span class="math inline">\(j\)</span> 是非周期的常返遍历态，那么根据定义 <span class="math inline">\(\mu_j \lt \infty\)</span>，且根据引理5， 当 <span class="math inline">\(n\rightarrow \infty\)</span> 时， <span class="math inline">\(p_{JJ}^{(n)}\)</span> 趋于一个非零常数，因此 <span class="math inline">\(\lim\limits_{n\rightarrow\infty} \sum_{k=0}^n p_{jj}^{(n)} = \infty\)</span>，从而状态 <span class="math inline">\(j\)</span> 是常返和遍历的，因而证明了引理6.</p><p><span class="math inline">\(\color{blue}{\textbf{引理 7 }}\)</span> 设状态 <span class="math inline">\(j\)</span> 是周期为 <span class="math inline">\(T\)</span> 的常返状态，那么 <span class="math display">\[p_{jj}^{(nd)} \rightarrow \frac{d}{\mu_j} \tag{31}\]</span></p><p><span class="math inline">\(\textbf{证明}\quad\)</span> 状态 <span class="math inline">\(j\)</span> 是周期为 <span class="math inline">\(d\)</span> 的，除非 <span class="math inline">\(n\)</span> 是周期 <span class="math inline">\(d\)</span> 的整数倍，否则 <span class="math inline">\(f_{jj}^{(n)}=0\)</span>，因此<span class="math inline">\(F_{ii}(z)\)</span> 仅包含 <span class="math inline">\(z^d\)</span> 的幂。设 <span class="math display">\[F_{jj}(z) = \varphi(z^d) \]</span> 所以，根据公式（23），我们可以得到 <span class="math display">\[P_{jj}(z) = \frac{1}{1-\varphi(z^d)} \]</span> 或 <span class="math display">\[ P_{jj}(z^{1/d}) = \frac{1}{1-\varphi(z)} = \sum_{n=0}^\infty p_{jj}^{(nd)}z^n \]</span> 且用类似于引理5证明方式中的推理，我们可以定义 <span class="math display">\[v_n = p_{jj}^{(nd)} - p_{jj}^{((n-1)d)} \]</span> 且可以得到 <span class="math display">\[ \sum_{k=0}^{n} v_k = p_{jj}^{(nd)} \]</span>，令 <span class="math display">\[ \begin{split}V(z) &amp;= \sum_{n=0}^\infty v_n z^n =P_{jj}(z) - zP_{jj}(z) \\&amp;=\frac{1}{1-\varphi({z^d})} - \frac{z}{1-\varphi(z^d)} \\&amp;= \frac{1-z}{1-\varphi(z^d)}\end{split}\]</span> 于是 <span class="math display">\[\begin{split} \lim\limits_{z\rightarrow 1} V(z) &amp;= \lim\limits_{z\rightarrow 1} \frac{1-z}{1-\varphi(z^d)} \cdot \frac{1-z^d}{1-z^d} = \lim\limits_{z\rightarrow 1} \frac{1-z^d}{1-\varphi(z^d)} \cdot \frac{1-z}{1-z^d} \\&amp;= \lim\limits_{z\rightarrow 1} \frac{1}{(1-\varphi(z^d))/(1-z^d)} \cdot \frac{1}{(1-z^d)/(1-z)} \\&amp;= \lim\limits_{z\rightarrow 1} \frac{1}{\varphi^{&#39;}(z^d)\cdot (\partial z^d)/(\partial z)} = \lim\limits_{z\rightarrow 1} \frac{1}{\varphi^{&#39;}(z)}\end{split}\]</span> 对 <span class="math inline">\(F_{jj}(z) = \varphi(z^d)\)</span> 做变换，得到 <span class="math inline">\(F_{jj}(z^{\frac{1}{d}}) = \varphi(z)\)</span> 两边求导，得到 <span class="math display">\[ F_{jj}^{&#39;} (z^{\frac{1}{d}}) \cdot \frac{1}{d} z^{\frac{1}{d} - 1} = \varphi^{&#39;} (z) \]</span> 带回公式，我们可以得到 <span class="math display">\[\begin{split}\lim\limits_{z\rightarrow 1} V(z) &amp;= \lim\limits_{z\rightarrow 1} \sum_{n=0}^\infty v_n z^n = \lim\limits_{z\rightarrow 1} \sum_{k=0}^n v_k = \lim\limits_{z\rightarrow 1} p_{jj}^{(nd)} \\&amp;= \lim\limits_{z\rightarrow 1} \frac{1}{\varphi^{&#39;}(z)} = \lim\limits_{z\rightarrow 1} \frac{d}{F_{jj}^{&#39;}(z)}\end{split}\]</span> 因此，引理7的证 <span class="math display">\[p_{ij}^{nT} \rightarrow \frac{1}{\varphi^{&#39;}(1)} = \frac{T}{F^{&#39;}_{jj}(1)} = \frac{T}{\mu_j} \]</span></p><h2 id="平稳分布">3.4 平稳分布</h2><p><span class="math inline">\(\color{green}{\textbf{定义 6 }}\)</span> 对于Markov链，概率分布 <span class="math inline">\(\{p_j, j \in \mathcal{S}\}\)</span> 称为平稳分布，如果 <span class="math display">\[p_j = \sum_{i\in\mathcal{S}} p_i p_{ij} \tag{32}\]</span> 可以理解为，对于 <span class="math inline">\((t-1)\)</span> 时刻的概率分布 <span class="math inline">\(\pi(t-1)\)</span>，通过概率转移矩阵 <span class="math inline">\(\pi(t)=\mathbf{P}\pi(t-1)\)</span> 计算得到新的概率分布，如果 <span class="math inline">\(\pi(t)=\pi(t-1)\)</span>，则称为是平稳分布。</p><p><span class="math inline">\(\color{green}{\textbf{定义 7 }}\)</span> 对于不可约非周期的马尔可夫链：</p><ol type="1"><li><p>若它是遍历的，则存在以下唯一的平稳分布 <span class="math display">\[\pi_j = \lim\limits_{n\rightarrow\infty} p_{jj}^{(n)} &gt;0 (j\in\mathcal{S}) \]</span></p></li><li><p>若状态都是瞬过的或者全为零常返的，则平稳分布不存在。</p></li></ol><p><span class="math inline">\(\textbf{证明}\quad\)</span> 对于第（1）条定理，对于遍历的Markov链，根据引理6可知 <span class="math display">\[\lim\limits_{n\rightarrow\infty} p_{ij}^{(n)} \ge 0 \]</span> 存在，记为 <span class="math inline">\(\pi_j\)</span>。首先证明 <span class="math inline">\(\{\pi_j, j\in\mathcal{S}\}\)</span> 是平稳分布。</p><p>由于 <span class="math display">\[\sum_{j\in\mathcal{S}} p_{ij}^{(n)} =1 \]</span>，则有 <span class="math display">\[\lim\limits_{n\rightarrow\infty} \sum_{j\in\mathcal{S}} p_{ij}^{(n)} =1 \]</span>，因此可以得到 <span class="math inline">\(\sum_{j\in\mathcal{S}}\pi_j=1\)</span>。</p><p>利用C-K方程，可以得到 <span class="math display">\[p_{ij}^{(n+1)} = \sum_{k\in\mathcal{S}} p_{ik}^{(n)} p_{kj} \]</span>。两边取极限可以得到 <span class="math display">\[\lim\limits_{n\rightarrow\infty}p_{ij}^{(n+1)} = \lim\limits_{n\rightarrow\infty}\sum_{k\in\mathcal{S}} p_{ik}^{(n)}p_{kj} = \sum_{k\in\mathcal{S}}\left[\lim\limits_{n\rightarrow\infty} p_{ik}^{(n)} \right] p_{kj} \]</span> 因此可以得到 <span class="math inline">\(\pi_j = \sum_{k\in\mathcal{S}} \pi_k p_{kj}\)</span>，因此 <span class="math inline">\(\{\pi_j, j\in\mathcal{S}\}\)</span> 是平稳分布。</p><p>再证明 <span class="math inline">\(\{\pi_j, j\in\mathcal{S}\}\)</span> 是唯一的平稳分布。假设还有另外一个平稳分布 <span class="math inline">\(\{\tilde{\pi}_j, j\in\mathcal{S}\}\)</span>，则根据 <span class="math inline">\(\tilde{pi}_j = \sum_{k\in\mathcal{S}} \tilde{\pi}_k p_{kj}\)</span> 归纳可以得到 <span class="math display">\[\tilde{pi}_j = \sum_{k\in\mathcal{S}} \tilde{\pi}_k p_{kj}^{(n)}, \quad n=1,2,\cdots\]</span> 令 <span class="math inline">\(n\rightarrow\infty\)</span>，对上式两端取极限，可以得到 <span class="math display">\[\tilde{\pi}_j = \sum_{i\in\mathcal{S}} \tilde{\pi}_i \lim\limits_{\rightarrow\infty} p_{ij}^{(n)} = \sum_{i\in\mathcal{S}} \tilde{\pi}_i\pi_j \]</span> 因为 <span class="math inline">\(\sum_{i\in\mathcal{S}} \tilde{\pi}_{i} = 1\)</span>，所以 <span class="math inline">\(\tilde{\pi}_j = \pi_j\)</span>，得证平稳分布唯一。</p><p>对于第（2）条定理，假设存在一个平稳分布 <span class="math inline">\(\{\pi_j, j\in\mathcal{S} \}\)</span>，则根据（1）中的证明可知， <span class="math display">\[ \pi_j \sum_{i\in\mathcal{S}} \pi_i p_{ij}^{(n)}, \quad n=1,2,\cdots \]</span> 成立，令 <span class="math inline">\(n\rightarrow \infty\)</span> 知道 <span class="math inline">\(p_{ij}^{(n)}\rightarrow 0\)</span>，则可以推导出 <span class="math inline">\(\pi_j = 0 (j\in \mathcal{S})\)</span>，这是不可能的。因此对于非常返或零常返的Markov链不存在平稳分布。</p><h1 id="markov-chain-and-monte-carlo">4 Markov Chain and Monte Carlo</h1><h2 id="核心思想基于采样的随机近似方法">4.1 核心思想:基于采样的随机近似方法</h2><p>在随机变量 <span class="math inline">\(\mathbf{x}\)</span> 的状态空间 <span class="math inline">\(\mathcal{S}\)</span> 上定义一个满足遍历定理的马尔可夫链 <span class="math inline">\(\mathbf{X}=\{\mathbf{x}_0, \mathbf{x}_1, \mathbf{x}_2, \cdots, \mathbf{x}_t, \cdots\}\)</span>，使其平稳分布就是抽样的目标分布 <span class="math inline">\(p(\mathbf{x})\)</span>。这样当时间趋于无穷时，样本分布趋近于平稳分布，样本的函数值的均值趋近于函数的数学期望。所以，当时间足够长时（时刻大于某个正整数 <span class="math inline">\(m\)</span>）zhihou de shijian (时刻小于某个正整数 <span class="math inline">\(n\)</span>, <span class="math inline">\(n&gt;m\)</span>)里随机游走得到的样本集合 <span class="math inline">\(\{\mathbf{x}_{m+1}, \mathbf{x}_{m+2}, \cdots, \mathbf{x}_{n}\}\)</span> 就是目标概率分布的抽样结果，得到的函数均值就是要计算的数学期望： <span class="math display">\[\hat{\mathbf{E}}[f(\mathbf{x})] = \frac{1}{n-m} \sum_{i=m+1}^n f(\mathbf{x}_i)\]</span> 到时刻 <span class="math inline">\(m\)</span> 为止的时间段被称为燃烧期。</p><p>我们希望构造的马尔可夫链是细致平稳的，即 <span class="math display">\[p(\mathbf{z}) q(\mathbf{z} \rightarrow \mathbf{z}^*) \alpha (\mathbf{z}^*) = p(\mathbf{z}^*) q(\mathbf{z}^* \rightarrow \mathbf{z}) \alpha (\mathbf{z})\]</span> 这样，我们可以将 <span class="math inline">\(p\)</span> 看作目标分布，<span class="math inline">\(q\)</span> 看作建议分布， <span class="math inline">\(\alpha\)</span> 看作接受分布。</p><p>假设要抽样的分布是 <span class="math inline">\(p(\mathbf{x})\)</span>，我们构建以 <span class="math inline">\(p(\mathbf{x}, \mathbf{x}^{&#39;})\)</span> 为转移核的马尔可夫链。 <span class="math display">\[p(\mathbf{x}, \mathbf{x}^{&#39;}) = q(\mathbf{x}, \mathbf{x}^{&#39;}) \alpha(\mathbf{x}, \mathbf{x}^{&#39;})\]</span> 其中 <span class="math inline">\(q(\mathbf{x}, \mathbf{x}^{&#39;})\)</span> 是不可约的，即其概率值恒不为0，同时是一个易于抽样的分布。接受分布 <span class="math inline">\(\alpha(\mathbf{x}, \mathbf{x}^{&#39;})\)</span> 可以表示如下： <span class="math display">\[\alpha(\mathbf{x}, \mathbf{x}^{&#39;}) = \min \left\{1, \frac{p(\mathbf{x}^{&#39;})q(\mathbf{x}^{&#39;}, \mathbf{x})}{p(\mathbf{x})q(\mathbf{x}, \mathbf{x}^{&#39;})}\right\}\]</span> 这样，转移核可以写为： <span class="math display">\[p(\mathbf{x}, \mathbf{x}^{&#39;}) = \begin{cases}q(\mathbf{x}, \mathbf{x}^{&#39;}), \quad &amp;p(\mathbf{x}^{&#39;})q(\mathbf{x}^{&#39;}, \mathbf{x}) \ge p(x)q(\mathbf{x}, \mathbf{x}^{&#39;}) \\q(\mathbf{x}^{&#39;}, \mathbf{x}) \frac{p(\mathbf{&#39;})}{p(\mathbf{x})}, \quad &amp; p(\mathbf{x}^{&#39;})q(\mathbf{x}^{&#39;}, \mathbf{x}) &lt; p(x)q(\mathbf{x}, \mathbf{x}^{&#39;}) \end{cases}\]</span> 个人理解，之所以要加入 <span class="math inline">\(\min\)</span> 限制，是因为转移核作为概率值要始终不超过1。</p><p><span class="math inline">\(\color{red}{\textbf{定理 3 }}\)</span> 通过上述方式构造的马尔可夫链是可逆的，即 <span class="math display">\[p(\mathbf{x})p(\mathbf{x}, \mathbf{x}^{&#39;}) = p(\mathbf{x}^{&#39;})p(\mathbf{x}^{&#39;}, \mathbf{x})\]</span> 且 <span class="math inline">\(p(\mathbf{x})\)</span> 是该马尔可夫链的平稳分布。</p><p><span class="math inline">\(\textbf{证明} \quad\)</span> 若 <span class="math inline">\(\mathbf{x} = \mathbf{x}^{&#39;}\)</span>，显然成立</p><p>如果 <span class="math inline">\(\mathbf{x}\neq\mathbf{x}^{&#39;}\)</span>， 则 <span class="math display">\[\begin{split}p(\mathbf{x})p(\mathbf{x}, \mathbf{x}^{&#39;}) &amp;= p(\mathbf{x}) q(\mathbf{x}, \mathbf{x}^{&#39;}) \min \left\{1, \frac{p(\mathbf{x}^{&#39;})q(\mathbf{x}^{&#39;}, \mathbf{x})}{p(\mathbf{x})q(\mathbf{x}, \mathbf{x}^{&#39;})}\right\} \\&amp;= \min \left\{ p(\mathbf{x})q(\mathbf{x}, \mathbf{x}^{&#39;}), p(\mathbf{x}^{&#39;})q(\mathbf{x}^{&#39;}, \mathbf{x}) \right\}\\&amp;= p(\mathbf{x}^{&#39;})q(\mathbf{x}^{&#39;}, \mathbf{x}) \min \left\{ \frac{p(\mathbf{x})q(\mathbf{x}, \mathbf{x}^{&#39;})}{p(\mathbf{x}^{&#39;})q(\mathbf{x}^{&#39;}, \mathbf{x})}, 1 \right\}\\&amp;= p(\mathbf{x}^{&#39;})q(\mathbf{x}^{&#39;}, \mathbf{x})\end{split}\]</span> 公式中导数第二行到最后一行的原因是因为按照接受概率的定义，<span class="math inline">\(\alpha(\mathbf{x}, \mathbf{x}^{&#39;}) \le 1\)</span>。 而上式中导数第二行中的左侧项则是反过来的，因此其值大于等于1且最小值为1。 显然定理中马尔可夫链可逆得证。 <span class="math display">\[\begin{split}\int p(\mathbf{x}) p(\mathbf{x}, \mathbf{x}^{&#39;}) d \mathbf{x} &amp;= \int p(\mathbf{x}^{&#39;}) p(\mathbf{x}^{&#39;}, \mathbf{x}) d \mathbf{x} \\&amp;= p(\mathbf{x}^{&#39;}) \int p(\mathbf{x}^{&#39;}, \mathbf{x}) d\mathbf{x} \\&amp;= p(\mathbf{x}^{&#39;})\end{split}\]</span> 因此定理得证。</p><p>这就是常用的 Metroplis-Hasting算法。</p><h2 id="metropolis-hasting-算法">4.1 Metropolis-Hasting 算法</h2><p>输入： 抽样的目标分布的密度函数 <span class="math inline">\(p(\mathbf{x})\)</span>， 函数 <span class="math inline">\(f(\mathbf{x})\)</span></p><p>输出： <span class="math inline">\(p(\mathbf{x})\)</span> 的随机样本 <span class="math inline">\(\{\mathbf{x}_{m+1}, \mathbf{x}_{m+2}, \cdots, \mathbf{x}_{n}\}\)</span>， 函数样本均值 <span class="math inline">\(f_{mn}\)</span></p><p>参数：收敛步数 <span class="math inline">\(m\)</span>, 迭代步数 <span class="math inline">\(n\)</span></p><p>（1）对于任意一个初始值 <span class="math inline">\(\mathbf{x}_0\)</span></p><p>（2）对 <span class="math inline">\(i=1,2,\cdots, n\)</span> 循环执行</p><p><span class="math inline">\(\quad\)</span> （a）设状态 <span class="math inline">\(\mathbf{x}_{i-1} = \mathbf{x}\)</span>，按照建议分布随机抽取一个候选状态 <span class="math inline">\(\mathbf{x}^{&#39;}\)</span></p><p><span class="math inline">\(\quad\)</span> （b） 计算接受概率 $(, ^{'}) = {1, } $</p><p><span class="math inline">\(\quad\)</span> （c）从区间（0，1）中按照均匀分布随机抽取一个数 <span class="math inline">\(u\)</span>，如果 <span class="math inline">\(u \le \alpha(\mathbf{x}, \mathbf{x}^{&#39;})\)</span>，则状态 <span class="math inline">\(\mathbf{x}_i = \mathbf{x}^{&#39;}\)</span>，否则 <span class="math inline">\(\mathbf{x}_i = \mathbf{x}\)</span></p><p>（3）得到样本集合 <span class="math inline">\(\{\mathbf{x}_{m+1}, \mathbf{x}_{m+2}, \cdots, \mathbf{x}_{n}\}\)</span></p><p>计算 <span class="math display">\[f_{mn} = \frac{1}{n-m} \sum_{i=m+1}^n f(\mathbf{x}_i)\]</span></p><p>这里要注意的是，我们这里使用的 <span class="math inline">\(p(\mathbf{x})\)</span> 实际上是 <span class="math inline">\(\hat{p}(\mathbf{x})\)</span>，是一个根据先验知识及似然概率推断出来的近似值，按理说还需要除以一个归一化因子，但实际上归一化因子很难求解，因此常常默认 <span class="math inline">\(p(\mathbf{x}) = \hat{p}(\mathbf{x})\)</span></p><h2 id="gibbs-采样">4.2 Gibbs 采样</h2><p>Gibbs采样是MH采样的一个特例，通常假设要采样的目标分布 <span class="math inline">\(p(\mathbf{x}^{(i)}) = p(z_1^{(i)},z_2^{(i)} , \cdots, z_K^{(i)})\)</span> 是高维的，需要一维一维的采，<strong>每次采样第<span class="math inline">\(i\)</span>维时，固定其他维</strong>。</p><p>假设多元变量联合概率分布为 <span class="math inline">\(p(\mathbf{x}) = p(x_1, x_2, \cdots, x_k)\)</span>， 吉布斯采样从一个初始样本 <span class="math inline">\(x^{(0)} = (x^{(0)}_1, x^{(0)}_2, \cdots, x^{(0)}_k)^T\)</span> 出发不断迭代，每一次迭代得到联合分布的一个样本 <span class="math inline">\(\mathbf{x}^{(i)} = (x^{(i)}_1, x^{(i)}_2, \cdots, x^{(i)}_k)^T\)</span>，最终样本序列为 <span class="math inline">\(\{\mathbf{x}^{(0)}, \mathbf{x}^{(1)}, \cdots, \mathbf{x}^{(k)} \}\)</span>。</p><p>在每次迭代中，依次对 <span class="math inline">\(k\)</span> 个随机变量中的一个变量进行随机抽样。如果在第 <span class="math inline">\(i\)</span> 次迭代中， 对滴 <span class="math inline">\(j\)</span> 个变量进行随机抽样，那么抽样的分布是满条件概率分布 <span class="math inline">\(p(x_j | x^{(i)}_{-j})\)</span>，这里 <span class="math inline">\(x^{(i)}_{-j}\)</span> 表示第 <span class="math inline">\(i\)</span> 次迭代中，变量 <span class="math inline">\(j\)</span> 以外的其他变量。</p><p>吉布斯采样算法如下：</p><p>输入： 目标概率分布的密度函数 <span class="math inline">\(p(\mathbf{x})\)</span>，函数 <span class="math inline">\(f(\mathbf{x})\)</span></p><p>输出： <span class="math inline">\(p(\mathbf{x})\)</span> 的随机样本 <span class="math inline">\(\{\mathbf{x}_{m+1}, \mathbf{x}_{m+2}, \cdots, \mathbf{x}_{n}\}\)</span>，函数样本均值 <span class="math inline">\(f_{mn}\)</span></p><p>参数： 收敛步数 <span class="math inline">\(m\)</span>， 迭代步数 <span class="math inline">\(n\)</span></p><p>（1） 初始化初始样本 <span class="math inline">\(x^{(0)} = (x^{(0)}_1, x^{(0)}_2, \cdots, x^{(0)}_k)^T\)</span></p><p>（2） 对 <span class="math inline">\(i\)</span> 循环执行。设第 <span class="math inline">\((i-1)\)</span> 迭代结束时的样本为 <span class="math inline">\(\mathbf{x}^{(i-1)} = (x^{(i-1)}_1, x^{(i-1)}_2, \cdots, x^{(i-1)}_k)^T\)</span>，则第 <span class="math inline">\(i\)</span> 次的迭代进行如下几步操作：</p><p><span class="math inline">\(\quad\)</span> 1) 由满条件分布 <span class="math inline">\(p(x_1|x^{(i-1)}_2, \cdots, x^{(i-1)}_k)\)</span> 抽取 <span class="math inline">\(x^{(i)}_1\)</span></p><p><span class="math inline">\(\quad \quad \vdots\)</span></p><p><span class="math inline">\(\quad\)</span> j) 由满条件分布 <span class="math inline">\(p(x_j|x^{(i)}_1, \cdots, x^{(i)}_{j-1}, x^{(i-1)}_{j+1}, \cdots, x^{(i-1)}_k)\)</span> 抽取 <span class="math inline">\(x^{(i)}_j\)</span></p><p><span class="math inline">\(\quad \quad \vdots\)</span></p><p><span class="math inline">\(\quad\)</span> k) 由满条件分布 <span class="math inline">\(p(x_k|x^{(i)}_1, \cdots, x^{(i)}_{k-1})\)</span> 抽取 <span class="math inline">\(x^{(i)}_k\)</span></p><p>得到第 <span class="math inline">\(i\)</span> 次的迭代值 <span class="math inline">\(\mathbf{x}^{(i)} = (x^{(i)}_1, x^{(i)}_2, \cdots, x^{(i)}_k)^T\)</span></p><ol start="3" type="1"><li><p>得到样本集合 <span class="math inline">\(\{\mathbf{x}_{m+1}, \mathbf{x}_{m+2}, \cdots, \mathbf{x}_{n}\}\)</span></p></li><li><p>计算 <span class="math display">\[f_{mn} = \frac{1}{n-m} \sum_{i=m+1}^{n} f(\mathbf{x}^{(i)})\]</span></p></li></ol><p>定义的减一分部是当前变量的满条件概率分布： <span class="math display">\[ q(\mathbf{x}, \mathbf{x}^{&#39;}) = p(x^{&#39;}_{j}|x_{-j}) \]</span> 这时，接受概率为 <span class="math inline">\(\alpha = 1\)</span> <span class="math display">\[\begin{split}\alpha(\mathbf{x}, \mathbf{x}^{&#39;}) &amp;= \min \left\{ 1, \frac{p(\mathbf{x}^{&#39;})q(\mathbf{x}^{&#39;}, \mathbf{x})}{p(\mathbf{x})q(\mathbf{x}, \mathbf{x}^{&#39;})} \right\} \\&amp;= \min \left\{ 1, \frac{p(x^{&#39;}_{-j}) p(x^{&#39;}_j|x^{&#39;}_{-j}) p(x_j|x^{&#39;}_{-j}) }{p(x_{-j}) p(x_j|x_{-j}) p(x^{&#39;}_j | x_{-j}) } \right\} = 1\end{split}\]</span> 上式是用到了 <span class="math inline">\(p(x_{-j}) = p(x^{&#39;}_{-j})\)</span> 和 <span class="math inline">\(p(\cdot | x_{-j}) = p(\cdot|x^{&#39;}_{-j})\)</span>，注意，这里的点表示的是当二者任意一致时成立。 转移核就是满条件概率分布 <span class="math display">\[p(\mathbf{x}, \mathbf{x}^{&#39;}) = p(x^{&#39;}_j|x_{-j})\]</span></p><h1 id="参考">参考</h1><ol type="1"><li><a href="http://www.tup.tsinghua.edu.cn/booksCenter/book_08132901.html">李航，统计机器学习（第2版），清华大学出版社</a></li><li><a href="http://www.crup.com.cn/Book/TextDetail?doi=1520e7e7-ac46-40b9-9864-1a917d9677dc">张波，应用随机过程（第5版），中国人民大学出版社</a></li><li><a href="https://baike.baidu.com/item/%E6%A6%82%E7%8E%87%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E4%B8%8E%E9%9A%8F%E6%9C%BA%E8%BF%87%E7%A8%8B/56914646?fr=aladdin">帕普里斯（著），保铮（译），概率、随机变量与随机过程（第4版），西安交通大学出版社</a></li><li><a href="https://space.bilibili.com/97068901">白板推导</a></li><li><a href="https://www.zhihu.com/question/46539491/answer/263442039">如何理解马尔科夫链中的常返态，非常返态，零常返，正常反，周期和非周期，有什么直观意义？ - uplow的回答 - 知乎</a></li><li><a href="https://www.zhihu.com/question/46539491/answer/2177451474">如何理解马尔科夫链中的常返态，非常返态，零常返，正常反，周期和非周期，有什么直观意义？ - LittleHealth的回答 - 知乎</a></li></ol>]]></content>
    
    
    <categories>
      
      <category>基础知识</category>
      
      <category>白板系列</category>
      
    </categories>
    
    
    <tags>
      
      <tag>采样算法</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>约束优化</title>
    <link href="/2022/11/18/KKT/"/>
    <url>/2022/11/18/KKT/</url>
    
    <content type="html"><![CDATA[<p>Karush-Kuhn-Tucker（KKT）条件是非线性规划最佳解的必要条件。KKT条件将Lagrange乘数法所涉及到的等式约束优化问题推广至不等式。在实际应用上，KKT条件一般不存在代数解。许多优化算法可提供数值计算选用。</p><h1 id="原始问题">1. 原始问题</h1><h2 id="等式约束优化问题">1.1 等式约束优化问题</h2><p><a id="sec1.1"></a></p><p>给定一个目标函数 $f:^n  $，我们希望找到 <span class="math inline">\(\mathbf{x}\in \mathbb{R}^n\)</span>，在满足约束条件 <span class="math inline">\(g(\mathbf{x})=0\)</span> 的前提下，使得 <span class="math inline">\(f(\mathbf{x})\)</span> 有最小值，这个约束优化问题记为：</p><p><span class="math display">\[\begin{split}&amp; \min \quad f(\mathbf{x}) \\&amp; \text{s.t.} \quad g(\mathbf{x})=0\end{split}\tag{1}\]</span></p><p>为了方便分析，假设 <span class="math inline">\(f\)</span> 与 <span class="math inline">\(g\)</span> 均为连续可导函数。Lagrange乘数法是等式约束优化问题的典型解法。定义Lagrange函数：</p><p><span class="math display">\[L(\mathbf{x}, \lambda) = f(\mathbf{x}) + \lambda g(\mathbf{x}) \tag{2}\]</span></p><p>其中 <span class="math inline">\(\lambda\)</span> 为Lagrange乘数。Lagrange乘数法将原本的约束优化问题转化为等价的无约束优化问题：</p><p><span class="math display">\[\min\limits_{\mathbf{x},\lambda} L(\mathbf{x}, \lambda) \tag{3}\]</span></p><p>计算 <span class="math inline">\(L\)</span> 对 <span class="math inline">\(\mathbf{x}\)</span> 和 <span class="math inline">\(\lambda\)</span> 的偏导数并设为零，可以得到最优解的必要条件：</p><p><span class="math display">\[\begin{split}&amp; \nabla_\mathbf{x} L = \frac{\partial L}{\partial \mathbf{x}} = \nabla f + \lambda \nabla g = 0\\&amp; \nabla_\lambda L = \frac{\partial L}{\partial \lambda} = g(\mathbf{x}) = 0\end{split}\tag{4}\]</span></p><p>其中，公式（4）第一式为定常方程式（Stationary Equation），第二式为约束条件，求解上面 n+1个方程式可以得到 <span class="math inline">\(L(\mathbf{x}, \lambda)\)</span> 的Stationary point <span class="math inline">\(\mathbf{x}^{*}\)</span> 以及 <span class="math inline">\(\lambda\)</span> 的值（正负均有可能）。</p><h2 id="不等式约束优化问题">1.2 不等式约束优化问题</h2><p><a id="sec1.2"></a></p><p>将约束等式 <span class="math inline">\(g(\mathbf{x})=0\)</span> 推广为不等式 <span class="math inline">\(g(\mathbf{x}) \le 0\)</span>，考虑如下问题： <span class="math display">\[\begin{split}&amp; \min \quad f(\mathcal{x})\\&amp; \text{s.t.} \quad g(\mathcal{x}) \le 0\end{split}\tag{5}\]</span> 约束不等式 <span class="math inline">\(g(\mathbf{x}) \le 0\)</span>称为原始可行性（primal feasibility），据此我们定义可行域（feasible region）<span class="math inline">\(K = \{\mathbf{x}\in\mathbb{R}^n | g(\mathbf{x}) \le 0\}\)</span>，假设Stationary Point <span class="math inline">\(\mathbf{x}^*\)</span> 为满足约束条件的最佳解，分为以下两种情况讨论：</p><ul><li><span class="math inline">\(g(\mathbf{x}^*) &lt; 0\)</span>，表示最佳解位于可行域 <span class="math inline">\(K\)</span> 内部，称为内部解（interior solution），这时约束条件是不起作用的（inactive）</li><li><span class="math inline">\(g(\mathbf{x}^*) = 0\)</span>，表示最佳解落在可行域 <span class="math inline">\(K\)</span> 边界，称为边界解（boundary solution），此时约束条件发挥作用（active）</li></ul><p>这两种情况的最佳解具有不同的必要条件：</p><ul><li><p>内部解：在约束条件不发挥作用（inactive）的情况下， <span class="math inline">\(g(\mathbf{x})\)</span> 不起作用，约束问题退化为无约束优化问题，因此驻点 <span class="math inline">\(\mathbf{x}^*\)</span> 满足 <span class="math inline">\(\nabla_\mathbf{x} f = 0\)</span> 且 <span class="math inline">\(\lambda=0\)</span>。</p></li><li><p>边界解：在约束条件发挥作用（active）的情形下，约束不等式变成等式 <span class="math inline">\(g(\mathbf{x})=0\)</span>，这与Lagrange乘数法的情况相同。这里可以认为存在 <span class="math inline">\(\lambda\)</span> 使得 <span class="math inline">\(\nabla_\mathbf{x} f = -\lambda \nabla_\mathbf{x}g\)</span>。这里 <span class="math inline">\(\lambda\)</span> 的正负号是有其意义的。因此我们希望最小化 <span class="math inline">\(f\)</span>，梯度 <span class="math inline">\(\nabla_\mathbf{x} f\)</span> （函数 <span class="math inline">\(f\)</span> 在 <span class="math inline">\(\mathbf{x}^*\)</span> 点方向导数最大值，即最陡上升方向）应该指向可行域 <span class="math inline">\(K\)</span> 的内部（因为最优解最小值是在边界取得的），但 <span class="math inline">\(\nabla_\mathbf{x} g\)</span> 指向可行域 <span class="math inline">\(K\)</span> 外部（即 <span class="math inline">\(g(\mathbf{x})&gt;0\)</span> 的区域，因为约束是小于等于0，继续向外走才能持续使目标函数 <span class="math inline">\(f\)</span> 的值下降），因此 <span class="math inline">\(\lambda \ge 0\)</span>， 称为对偶可行性（dual feasibility）。</p></li></ul><h2 id="多个约束等式与约束不等式">1.3 多个约束等式与约束不等式</h2><p>根据<a href="#sec1.1">章节1.1</a>和<a href="#sec1.2">章节1.2</a>，我们可以推广至多个约束等式与约束不等式的情况，考虑标准约束优化（或者称非线性规划）：</p><p><span class="math display">\[\begin{split}\min\limits_{\mathbf{x}\in \mathbb{R}^n} \quad &amp;f(\mathbf{x})\\\text{s.t.} \quad &amp; c_i(\mathbf{x}) \le 0, \quad i=1,2,\ldots,k \\&amp; h_j(\mathbf{x}) = 0, \quad j = 1,2,\ldots, l\end{split}\tag{6}\]</span> 我们称上式为约束最优化问题为原始最优化问题或原始问题。</p><p>首先，引入Generalized Lagrange Function（广义拉格朗日函数）： <span class="math display">\[L(\mathbf{x}, \alpha, \beta) = f(\mathbf{x}) + \sum_{i=1}^k \alpha_i c_i(\mathbf{x}) + \sum_{j=1}^l \beta_j h_j(\mathbf{x}) \tag{7}\]</span> 这里 <span class="math inline">\(\alpha_i, \beta_j\)</span> 是Lagrange乘子，<span class="math inline">\(\alpha_i&gt;\ge 0\)</span>，考虑 <span class="math inline">\(\mathbf{x}\)</span> 的函数： <span class="math display">\[\theta_P(\mathbf{x}) = \max\limits_{\alpha, \beta; \alpha_i \ge 0} L(\mathbf{x}, \alpha, \beta) \tag{8}\]</span> 这里，下标 <span class="math inline">\(P\)</span> 表示原始问题。</p><p>假设给定某个 <span class="math inline">\(\mathbf{x}\)</span>，如果它违反原始问题的约束条件，即存在某个 <span class="math inline">\(i\)</span> 使得 <span class="math inline">\(c_i(\mathbf{x})&gt;0\)</span> 或者存在某个 <span class="math inline">\(j\)</span> 使得 <span class="math inline">\(h_j(\mathbf{x}) \neq 0\)</span>，那么就有</p><p><span class="math display">\[\theta_P(\mathbf{x}) = \max\limits_{\alpha, \beta; \alpha_i\ge 0} \left[f(\mathbf{x}) + \sum_{i=1}^k \alpha_i c_i (\mathbf{x}) + \sum_{j=1}^l \beta_j h_j (\mathbf{x}) \right] = + \infty \tag{9}\]</span> 因为如果某个 <span class="math inline">\(i\)</span> 使得约束 <span class="math inline">\(c_i(\mathbf{x})&gt;0\)</span>，则可令 <span class="math inline">\(\alpha_i \rightarrow + \infty\)</span>；若某个 <span class="math inline">\(j\)</span> 使得 <span class="math inline">\(h_j(\mathbf{x}) \neq 0\)</span>，则可令 <span class="math inline">\(\beta_j\)</span> 使 <span class="math inline">\(\beta_j h_j (\mathbf{x}) \rightarrow + \infty\)</span>， 而将其余各个 <span class="math inline">\(\alpha_i, \beta_j\)</span> 均取值为0.</p><p>相反地，如果 <span class="math inline">\(\mathbf{x}\)</span> 满足公式（6）中的约束条件式，则根据公式（7）和公式（8）可以得到： <span class="math display">\[\theta_P(\mathbf{x}) = \begin{cases}f(\mathbf{x}), \quad &amp; \mathbf{x} \text{满足原始问题约束}\\+ \infty, \quad &amp;\text{其他}\end{cases}\tag{10}\]</span> 所以，如果考虑极小化问题 <span class="math display">\[\min\limits_{\mathbf{x}}\theta_P(\mathbf{x}) = \min\limits_{\mathbf{x}} \max\limits_{\alpha, \beta;\alpha_i \ge 0} L(\mathbf{x}, \alpha, \beta) \tag{11}\]</span> 公式（11）是与公式（6）原始最优化问题是等价的，即它们有相同的解。问题 <span class="math inline">\(\min\limits_{\mathbf{x}} \max\limits_{\alpha, \beta;\alpha_i \ge 0} L(\mathbf{x}, \alpha, \beta)\)</span> 被称为广义拉格朗日函数的极小极大问题。这样一来，就把原始最优化问题表示为广义拉格朗日函数的极小极大问题。为了方便，可以定义原始问题的最优值 <span class="math display">\[p^* = \min\limits_{\mathbf{x}} \theta_P(\mathbf{x}) \tag{12}\]</span> 称为原始问题的值。</p><h1 id="对偶问题">2. 对偶问题</h1><p>定义 <span class="math display">\[\theta_D(\alpha, \beta) = \min\limits_{\mathbf{x}} L(\mathbf{x}, \alpha, \beta) \tag{13}\]</span> 再考虑极大化公式（13），即 <span class="math display">\[\max\limits_{\alpha, \beta;\alpha_i \ge 0} \theta_D(\alpha, \beta) = \max\limits_{\alpha,\beta;\alpha_i \ge 0} \min \limits_{\mathbf{x}} L(\mathbf{x}, \alpha, \beta) \tag{14}\]</span> 问题 <span class="math inline">\(\max\limits_{\alpha,\beta;\alpha_i \ge 0} \min \limits_{\mathbf{x}} L(\mathbf{x}, \alpha, \beta)\)</span> 被称为广义拉格朗日函数的极大极小问题。</p><p>可以将广义拉格朗日函数的极大极小问题表示为约束最优化问题： <span class="math display">\[\begin{split}&amp;\max\limits_{\alpha, \beta} \theta_D(\alpha, \beta) = \max\limits_{\alpha, \beta}\min\limits_{\mathbf{x}} L(\mathbf{x}, \alpha, \beta) \\&amp;\text{s.t.} \quad \alpha_i \ge 0, \quad i=1,2,\ldots,k\end{split}\tag{15}\]</span> 上式被称为原始问题的对偶问题，定义对偶问题的最优值 <span class="math display">\[d^* = \max\limits_{\alpha, \beta; \alpha_i \ge 0} \theta_D (\alpha, \beta) \tag{16}\]</span> 为对偶问题的值。</p><blockquote><p><strong>为什么要引入对偶问题？</strong></p><ul><li><p>对偶问题交换了求极值的顺序，先求解的是函数 <span class="math inline">\(f(\mathbf{x})\)</span> 的极小值（自变量为 <span class="math inline">\(\mathbf{x}\)</span> ），等价成梯度为0的约束条件，并将难以求解的约束条件扔到目标函数的位置上去。</p></li><li><p>在定义域为凸集的前提下，转换后的对偶问题的自变量是约束条件系数构成的线性函数，一定是凸问题。</p></li></ul></blockquote><h1 id="原问题与对偶问题之间的关系">3. 原问题与对偶问题之间的关系</h1><blockquote><p><strong>定理1:</strong> 如果原始问题和对偶问题都有最优值，则 <span class="math display">\[d^* = \max\limits_{\alpha, \beta;\alpha_i \ge 0} \min\limits_{\mathbf{x}} L(\mathbf{x}, \alpha, \beta) \le \min\limits_{\mathbf{x}}\max\limits_{\alpha, \beta;\alpha_i \ge 0} L(\mathbf{x}, \alpha, \beta) = p^* \tag{17} \]</span></p></blockquote><p><strong>证明：</strong> 根据公式（9）和公式（13）的定义，我们可以得到： <span class="math display">\[\theta_D(\alpha, \beta) =\min\limits_{\mathbf{x}} L(\mathbf{x}, \alpha, \beta) \le L(\mathbf{x}, \alpha, \beta) \le \max\limits_{\alpha, \beta; \alpha_i \ge 0} L(\mathbf{x}, \alpha, \beta) = \theta_P(\mathbf{x}) \tag{18}\]</span> 即 <span class="math display">\[\theta_D(\alpha, \beta) \le \theta_P(\mathbf{x}) \tag{19}\]</span> 由于原始问题和对偶问题都有最优值，所以： <span class="math display">\[\max\limits_{\alpha,\beta;\alpha_i \ge 0}\theta_D(\mathbf{x}) \le \min\limits_{\mathbf{x}} \theta_P(\mathbf{x}) \tag{20} \]</span> 因此，定理得证。</p><blockquote><p><em>推论1:</em> 设 <span class="math inline">\(x^*, \alpha^*, \beta^*\)</span> 分别是原始问题（公式（6））和对偶问题（公式（15））的可行解，并且 <span class="math inline">\(d^* = p^*\)</span>， 则 <span class="math inline">\(x^*, \alpha^*, \beta^*\)</span> 分别是原始问题和对偶问题的最优解。</p></blockquote><blockquote><p><strong>定理2:</strong> 考虑原始问题（公式（6））和对偶问题（公式（15））。假设函数 <span class="math inline">\(f(\mathbf{x})\)</span> 和 <span class="math inline">\(c_i(\mathbf{x})\)</span> 是凸函数，<span class="math inline">\(h_j(\mathbf{x})\)</span> 是仿射函数，并且假设不等式约束 <span class="math inline">\(c_i(\mathbf{x})\)</span> 是严格执行的，即存在 <span class="math inline">\(\mathbf{x}\)</span> ，对所有 <span class="math inline">\(i\)</span> 有 <span class="math inline">\(c_i(\mathbf{x}) &lt;0\)</span>， 则存在 <span class="math inline">\(x^*, \alpha^*, \beta^*\)</span>，使 <span class="math inline">\(\mathbf{x}^*\)</span> 是原始问题的解， <span class="math inline">\(\alpha^*\)</span> 和 <span class="math inline">\(\beta^*\)</span> 是对偶问题的解，并且 <span class="math display">\[p^* = d^* = L(\mathbf{x}^*, \alpha^*, \beta^*) \tag{21}\]</span></p></blockquote><blockquote><p><strong>定理3:</strong> 对原始问题（公式（6））和对偶问题（公式（15）），假设函数 <span class="math inline">\(f(\mathbf{x})\)</span> 和 <span class="math inline">\(c_i(\mathbf{x})\)</span> 是凸函数，<span class="math inline">\(h_j(\mathbf{x})\)</span> 是仿射函数，并且假设不等式约束 <span class="math inline">\(c_i(\mathbf{x})\)</span> 是严格执行的， 则存在 <span class="math inline">\(x^*, \alpha^*, \beta^*\)</span> 分别是原始问题和对偶问题的解的充分必要条件是下面的 Karush-Kuhn-Tucker（KKT）条件</p></blockquote><p><span class="math display">\[ \nabla_\mathbf{x} L(\mathbf{x}^*, \alpha^*, \beta^*)=0 \tag{22-1} \]</span> <span class="math display">\[ c_i(\mathbf{x}) \le 0, \quad i =1,2,\ldots,k \tag{22-2}\]</span> <span class="math display">\[ h_j(\mathbf{x}^*) = 0, \quad j=1,2,\ldots, l \tag{22-3}\]</span> <span class="math display">\[\alpha_i^* \ge 0, \quad i=1,2,\ldots,k \tag{22-4}\]</span> <span class="math display">\[ \alpha_i^* c_i(\mathbf{x}^*)=0, \quad i=1,2,\ldots,k \tag{22-5} \]</span> 特别指出，公式（22-5）被称为KKT的对偶互补条件，由此条件可知，如果 <span class="math inline">\(\alpha_i^* &gt;0\)</span>， 则 <span class="math inline">\(c_i(\mathbf{x}^*) = 0\)</span></p><h1 id="kkt条件的解释">4. KKT条件的解释</h1><h2 id="必要性证明">4.1 必要性证明</h2><p>公式（22）为KKT条件，下面对这5个条件逐个进行解释： + 公式（22-1）为广义拉格朗日函数的梯度，表示最优解处的梯度为0. + 公式（22-2）和公式（22-3）分别是愿问题的不等式约束和等式约束，最优解显然应当满足 + 公式（22-4）是对偶问题的不等式约束，表示对偶可行。即当 <span class="math inline">\(\alpha \ge 0\)</span> 时，<span class="math inline">\(L(\mathbf{x}, \alpha, \beta) \le f(\mathbf{x})\)</span>，对偶函数才能给出愿问题的最优值下界。 + 公式（22-5）被称为互补松弛性，推导过程如公式（23）所示： - 第一行：强对偶条件成立，对偶间隙为0 - 第二行：根据公式（13）展开对偶函数 - 第三行：函数的最小值不会超过定义域内任意一点函数值 - 第四行：等式约束 <span class="math inline">\(h_j(\mathbf{x})\)</span> 为0， 而不等式约束 <span class="math inline">\(c_i(\mathbf{x})\le 0\)</span> 且拉格朗日乘子 <span class="math inline">\(\alpha \ge 0\)</span>， 因此成立 <span class="math display">\[\begin{split}f(\mathbf{x}^*) &amp;= \theta_D(\alpha^*, \beta^*) \\&amp;= \min\limits_{\mathbf{x}} \left( f(\mathbf{x}) + \sum_{i=1}^k \alpha_i^* c_i(\mathbf{x}) + \sum_{j=1}^l \beta_j^* h_j(\mathbf{x}) \right) \\&amp; \le f(\mathbf{x^*}) + \sum_{i=1}^k \alpha_i^* c_i(\mathbf{x}) + \sum_{j=1}^l \beta_j^* h_j(\mathbf{x^*}) \\&amp; \le f(\mathbf{x}^*)\end{split}\tag{23}\]</span> - 其中</p><h2 id="充分性证明">4.2 充分性证明</h2><ul><li>公式（22-1）是梯度为0的条件。</li><li>公式（22-2）和公式（22-3）为原问题的不等式约束和等式约束，保证解的可行</li><li>公式（22-4）为对偶可行条件，</li><li>公式（22-5）为互补松弛条件</li></ul><p>所以可以有公式（24）的推断： + 第一行为对偶函数在 <span class="math inline">\((\alpha^*, \beta^*)\)</span> 处的取值 + 第二行为拉格朗日函数的定义 + 第三行是因为互补松弛条件和等式约束</p><p><span class="math display">\[\begin{split}\theta_D(\alpha^*, \beta^*) &amp;= L(\mathbf{x}^*, \alpha^*, \beta^*) \\&amp;= f(\mathbf{x}^*) + \sum_{i=1}^k \alpha_i^* c_i(\mathbf{x}) + \sum_{j=1}^l \beta_j^* h_j(\mathbf{x^*})\\ &amp;= f(\mathbf{x}^*)\end{split}\tag{24}\]</span></p><h1 id="举例">5. 举例</h1><p>考虑如下问题：</p><p><span class="math display">\[\begin{split}\min \quad &amp; x_1^2 + x_2^2 \\\text{s.t.} \quad &amp; x_1 + x_2 = 1\\&amp; x_2 \le \eta\end{split}\tag{25}\]</span> 拉格朗日函数为： <span class="math display">\[L(x_1, x_2, \alpha, \beta) = x_1^2 + x_2^2 + \alpha(x_2 - \eta) + \beta(1 - x_1 -x_2)\tag{26}\]</span> KKT 方程组如下 <span class="math display">\[\begin{split}&amp; \frac{\partial L}{\partial x_i} = 0, \quad i=1,2 \\&amp; x_1 + x_2 = 1\\&amp; x_2 - \eta \le 0 \\&amp; \alpha \ge 0 \\&amp; \alpha(x_2 - \eta) = 0\end{split}\tag{27}\]</span> 对公式（27）求解可得 <span class="math inline">\(\frac{\partial L}{\partial x_1} = 2x_1 - \beta = 0\)</span>, <span class="math inline">\(\frac{\partial L}{\partial x_2} = 2x_2-\beta+\alpha=0\)</span>。分别求解出 <span class="math inline">\(x_1 = \frac{\beta}{2}\)</span>, <span class="math inline">\(x_2 = \frac{\beta}{2} - \frac{\alpha}{2}\)</span>；代入约束等式，可以得到 <span class="math inline">\(x_1 = \frac{\alpha}{4} + \frac{1}{2}\)</span>, <span class="math inline">\(x_2 = -\frac{\alpha}{4} + \frac{1}{2}\)</span>；代入约束不等式 <span class="math inline">\(-\frac{\alpha}{4} + \frac{1}{2} \le \eta\)</span>，以下分三种情况讨论：</p><ul><li><span class="math inline">\(\eta &gt; \frac{1}{2}\)</span>: 可以看出 <span class="math inline">\(\alpha = 0 &gt; 2-4\eta\)</span> 满足所有KKT条件，约束不等式未发挥作用（inactive），<span class="math inline">\(x_1^* = x_2^* = \frac{1}{2}\)</span> 是内部解，目标函数的极小值为 <span class="math inline">\(\frac{1}{2}\)</span></li><li><span class="math inline">\(\eta = \frac{1}{2}\)</span>: <span class="math inline">\(\alpha = 0= 2-4\eta\)</span> 满足所有KKT条件，<span class="math inline">\(x_1^* = x_2^* = \frac{1}{2}\)</span> 是边界解，因此 <span class="math inline">\(x_2^* = \eta\)</span></li><li><span class="math inline">\(\eta &lt; \frac{1}{2}\)</span>: 这时约束不等式是生效的（active），<span class="math inline">\(\alpha = 2-4\eta &gt;0\)</span>，则 <span class="math inline">\(x_1^* = 1-\eta\)</span> 且 <span class="math inline">\(x_2^* = \eta\)</span>， 目标函数极小值是 <span class="math inline">\((1-\alpha)^2 + \alpha^2\)</span></li></ul><h1 id="参考">参考</h1><ol type="1"><li><a href="http://www.tup.tsinghua.edu.cn/booksCenter/book_08132901.html">李航，统计学习方法（第二版）</a></li><li><a href="https://zhuanlan.zhihu.com/p/62420593">支持向量机原理详解(四): KKT条件(Part I) - 知乎</a></li><li><a href="https://zhuanlan.zhihu.com/p/38163970">Karush-Kuhn-Tucker (KKT)条件 - 知乎</a></li></ol>]]></content>
    
    
    <categories>
      
      <category>基础知识</category>
      
    </categories>
    
    
    <tags>
      
      <tag>约束优化</tag>
      
      <tag>最优化</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Denoising Diffusion Probabilistic Model (DDPM) 论文阅读</title>
    <link href="/2022/10/29/DDPM/"/>
    <url>/2022/10/29/DDPM/</url>
    
    <content type="html"><![CDATA[<h1 id="基本原理介绍">基本原理介绍</h1><p>Diffusion模型和VAE、GAN、流模型等一样都属于生成类模型。Diffusion模型在前向阶段<span class="math inline">\(q(\mathbf{x}_t|\mathbf{x}_{t-1})\)</span>逐渐对图像加噪声，直至图像被完全破坏成高斯噪声，然后在逆向阶段<span class="math inline">\(p_{\theta}(\mathbf{x}_{t-1}|\mathbf{x}_t)\)</span>学习从高斯噪声逐渐还原为原始图像的过程，如图1所示，</p><figure><img src="/2022/10/29/DDPM/DDPM_1.png" alt="图1 DDPM前向与逆向过程"><figcaption aria-hidden="true">图1 DDPM前向与逆向过程</figcaption></figure><h2 id="forward-process-前向阶段">Forward Process （前向阶段）</h2><p>作者认为前向过程中图像<span class="math inline">\(\mathbf{x}_t\)</span>只和上一时刻的<span class="math inline">\(\mathbf{x}_{t-1}\)</span>相关，遵循马尔可夫过程，满足如下性质：</p><p><span class="math display">\[ q(\mathbf{x}_{1:T}|\mathbf{x}_0)=\prod^T_{t=1}q(\mathbf{x}_t | \mathbf{x}_{t-1}) \tag{1}\]</span> <span class="math display">\[ q(\mathbf{x}_t|\mathbf{x}_{t-1}) = \mathcal{N}(\mathbf{x}_t; \sqrt{1-\beta_t} \mathbf{x}_{t-1}, \beta_t \mathbb{I}) \tag{2}\]</span></p><p>其中参数 <span class="math inline">\(\beta_t\)</span> 表示第t时刻高斯分布的方差超参数，并满足 <span class="math inline">\(\beta_1\lt\beta_2\lt\cdots\lt \beta_T\)</span>。公式（2）中 <span class="math inline">\(\sqrt{1-\beta_t}\)</span> 是均值系数。任意时刻可以通过 <strong>重参数技巧</strong> 方法采样得到<span class="math inline">\(\mathbf{x}_t\)</span>。</p><blockquote><p><strong>Reparameterization trick 重参数技巧</strong> 该方法是为了解决随机采样样本这一过程无法求导的问题，例如我们要从某个分布（如高斯分布 <span class="math inline">\(z\sim\mathcal{N}(z;\mu,\sigma^2\mathbb{I})\)</span>）中随机采样一个样本，这个过程无法反传梯度。通常的做法是通过引入随机变量 <span class="math inline">\(\epsilon\sim\mathcal{N}(0,\mathcal{I})\)</span>，使得 <span class="math inline">\(z=\mu+\sigma\odot\epsilon\)</span>。这样一来，<span class="math inline">\(z\)</span> 仍然具有随机性，且服从高斯分布 <span class="math inline">\(\mathcal{N}(\mu, \sigma^2\mathcal{I})\)</span>，同时 <span class="math inline">\(\mu\)</span>与 <span class="math inline">\(\sigma\)</span>可导。</p></blockquote><blockquote><p><strong>正态分布性质</strong> 给定两个服从正态分布的独立随机变量 <span class="math inline">\(X \sim \mathcal{N}(\mu_X, \sigma_X^2)\)</span>, <span class="math inline">\(Y \sim \mathcal{N}(\mu_Y, \sigma^2_Y)\)</span>。这两个分布的加和为 <span class="math inline">\(Z=X+Y\)</span> 同样服从正态分布 <span class="math inline">\(Z \sim \mathcal{N}(\mu_X + \mu_Y, \sigma_X^2 + \sigma_Y^2)\)</span>。</p></blockquote><h3 id="根据-mathbfx_0-推断-mathbfx_t">根据 <span class="math inline">\(\mathbf{x}_0\)</span> 推断 <span class="math inline">\(\mathbf{x}_t\)</span></h3><p>根据公式（2）的采样方法，生成随机变量 <span class="math inline">\(\epsilon_t \sim \mathcal{N}(0,\mathbb{I})\)</span>， 然后令 <span class="math inline">\(\alpha_t = 1 - \beta_t\)</span>， 以及 <span class="math inline">\(\overline{\alpha}_t = \prod^T_{i=1} \alpha_i\)</span>， 按照公式（2）中给定的系数，可以做如下推导： <span class="math display">\[\begin{split}\mathbf{x}_t &amp;= \sqrt{1-\beta_t} \mathbf{x}_{t-1} + \beta_t \epsilon_1\\&amp;= \sqrt{\alpha_t} \mathbf{x}_{t-1} + \sqrt{1-\alpha_t} \epsilon_1 \\&amp;= \sqrt{\alpha_t}(\sqrt{\alpha_{t-1}}\mathbf{x}_{t-2} + \sqrt{1-\alpha_{t-1}} \epsilon_2) + \sqrt{1-\alpha_t} \epsilon_1 \\&amp;= \sqrt{\alpha_t \alpha_{t-1}} \mathbf{x}_{t-2} + (\sqrt{\alpha_t (1-\alpha_{t-1})} \epsilon_2 + \sqrt{1-\alpha_t} \epsilon_1) \\&amp;= \sqrt{\alpha_t \alpha_{t-1}} \mathbf{x}_{t-2} + \sqrt{1-\alpha_t \alpha_{t-1}} \tilde{\epsilon_2} \\&amp;= \cdots \\&amp;= \sqrt{\overline{\alpha}_t} \mathbf{x}_0 + \sqrt{1-\overline{\alpha}_t} \tilde{\epsilon_t}\end{split} \tag{3} \]</span> 上式的关键在于第4行到第5行的转换。依赖的正是正态分布性质。<span class="math inline">\(\epsilon_1, \epsilon_2 \sim \mathcal{N}(0, \mathbb{I})\)</span>， 因此，可以做出如下推断： <span class="math display">\[\sqrt{\alpha_t (1 - \alpha_{t-1})} \epsilon_2 \sim \mathcal{N}(0, \alpha_t (1-\alpha_{t-1}) \mathbb{I}) \tag{4}\]</span> <span class="math display">\[\sqrt{1-\alpha_t} \epsilon_1 \sim \mathcal{N}(0, (1-\alpha_t)\mathbb{I}) \tag{5}\]</span> <span class="math display">\[ \begin{split}\sqrt{\alpha_t (1 - \alpha_{t-1})} \epsilon_2 + \sqrt{1-\alpha_t} \epsilon_1 &amp; \sim \mathcal{N}(0, \left[\alpha_t(1-\alpha_{t-1}) + (1-\alpha_t)\right])\\ &amp;= \mathcal{N}(0, (1-\alpha_t \alpha_{t-1})\mathbb{I})\end{split}\tag{6}\]</span> 因此公式（3）可以表示如下： <span class="math display">\[q(\mathbf{x}_t|\mathbf{x}_0) = \mathcal{N}(\mathbf{x}_t;\sqrt{\overline{\alpha}_t} \mathbf{x}_0, (1-\overline{\alpha}_t) \mathbb{I}) \tag{7}\]</span> 根据前文，参数 <span class="math inline">\(\beta_t \in (0,1)\)</span> 且 <span class="math inline">\(\beta_1 \lt \beta_2 \lt \cdots \lt \beta_T\)</span>，<span class="math inline">\(\alpha_t = 1 - \beta_t\)</span> 且 <span class="math inline">\(\alpha_1 \gt \alpha_2 \gt \cdots \gt \alpha_T\)</span>。由于 <span class="math inline">\(\overline{\alpha}_t = \prod^T_{i=1} \alpha_i\)</span>，因此，当 <span class="math inline">\(T \rightarrow \infty\)</span>，<span class="math inline">\(\overline{\alpha}_t \rightarrow 0\)</span> 且 <span class="math inline">\((1-\overline{\alpha}_t) \rightarrow 1\)</span>，此时，公式（7）趋向于标准正态分布 <span class="math inline">\(\mathbf{x}_T \sim \mathcal{N}(0, \mathbb{I})\)</span>。因此，公式（2）中均值前要乘以系数 <span class="math inline">\(\sqrt{1-\beta_t}\)</span>。</p><h2 id="reverse-process-逆向过程">Reverse Process 逆向过程</h2><p>前向（扩散）过程是给数据添加噪音，逆向过程就是去噪音过程。逆向过程中，我们以高斯噪声 <span class="math inline">\(\mathbf{x}_T \sim \mathcal{N}(0, \mathbb{I})\)</span> 作为输入，如果能够得到逆向过程的分布 <span class="math inline">\(q(\mathbf{x}_{t-1}|\mathbf{x}_t)\)</span>， 那么我们能够得到真实的样本。根据文献 <a href="https://link.springer.com/chapter/10.1007/978-3-319-16859-3_42">On the theory of stochastic processes, with particular reference to applications</a>，如果 <span class="math inline">\(q(\mathbf{x}_t|\mathbf{x}_{t-1})\)</span> 满足高斯分布且 <span class="math inline">\(\beta_t\)</span> 足够小，<span class="math inline">\(q(\mathbf{x}_{t-1}|\mathbf{x}_t)\)</span>仍然是高斯分布。 由于无法直接推断 <span class="math inline">\(q(\mathbf{x}_{t-1}|\mathbf{x}_t)\)</span>，因此使用深度学习模型 <span class="math inline">\(p_\theta\)</span> 去拟合 <span class="math inline">\(q(\mathbf{x}_{t-1}|\mathbf{x}_t)\)</span>，模型参数为 <span class="math inline">\(\theta\)</span>。</p><p><span class="math display">\[p_\theta(\mathbf{x}_{0:T}) = p_\theta(\mathbf{x}_1, \mathbf{x}_2, \ldots, \mathbf{x}_T) = p(\mathbf{x}_T) \prod ^T_{t=1} p_\theta (\mathbf{x}_{t-1}|\mathbf{x}_t) \tag{8}\]</span></p><p><span class="math display">\[p_\theta(\mathbf{x}_{t-1}|\mathbf{x}_t) = \mathcal{N}(\mathbf{x}_{t-1};\mu_\theta(\mathbf{x}_t, t), \Sigma_\theta(\mathbf{x}_t, t)) \tag{9}\]</span></p><h3 id="求解条件概率-qmathbfx_t-1mathbfx_t-mathbfx_0">求解条件概率 <span class="math inline">\(q(\mathbf{x}_{t-1}|\mathbf{x}_t, \mathbf{x}_0)\)</span></h3><p>虽然无法直接求到 <span class="math inline">\(q(\mathbf{x}_{t-1}|\mathbf{x}_t)\)</span>（注意这里是 <span class="math inline">\(q\)</span> 而不是模型的 <span class="math inline">\(p_\theta\)</span>)，在知道初始分布 <span class="math inline">\(\mathbf{x}_0\)</span> 的情况下，可以通过贝叶斯公式得到 <span class="math inline">\(q(\mathbf{x}_{t-1}|\mathbf{x}_t, \mathbf{x}_0)\)</span> 为:</p><p><span class="math display">\[q(\mathbf{x}_{t-1}|\mathbf{x}_t, \mathbf{x}_0) = \mathcal{N}(\mathbf{x}_{t-1}; \textcolor{blue}{\tilde{\mu_t}} (\mathbf{x}_t, \mathbf{x}_0), \textcolor{red} {\tilde{\beta_t}} \mathbb{I}) \tag{10}\]</span></p><blockquote><p><strong>三变量贝叶斯公式</strong> <span class="math display">\[P(x|y,z) = \frac{P(y|x,z)P(x|z)}{P(y|z)} = \frac{P(z|x,y)P(x|y)}{P(z|y)}\]</span></p></blockquote><p>根据上文公式（2）和（7）可知，</p><p><span class="math display">\[q(\mathbf{x}_t|\mathbf{x}_{t-1}) = \mathcal{N}(\mathbf{x}_t; \sqrt{1-\beta_t} \mathbf{x}_{t-1}, \beta_t \mathbb{I}) = \exp \left( -\frac{(\mathbf{x}_t - \sqrt{\alpha_t} \mathbf{x}_{t-1})^2}{2\beta_t} \right)\]</span></p><p><span class="math display">\[q(\mathbf{x}_t|\mathbf{x}_0) = \mathcal{N}(\mathbf{x}_t; \sqrt{\overline{\alpha}_t} \mathbf{x}_0, (1-\overline{\alpha}_t) \mathbb{I}) = \exp \left( -\frac{(\mathbf{x}_t - \sqrt{\overline{\alpha}_t} \mathbf{x}_0)^2}{2\beta_t} \right)\]</span></p><p>因此，公式（10）完整推导过程如下： <span class="math display">\[\begin{split}&amp;q(\mathbf{x}_{t-1}|\mathbf{x}_t, \mathbf{x}_0) = q(\mathbf{x}_t|\mathbf{x}_{t-1}, \mathbf{x}_0)\frac{q(\mathbf{x}_{t-1}|\mathbf{x}_0)}{q(\mathbf{x}_t|\mathbf{x}_0)}\\&amp; \propto \exp\left( -\frac{1}{2}\left( \frac{(\mathbf{x}_t - \sqrt{\alpha_t} \mathbf{x}_{t-1})^2}{\beta_t} + \frac{(\mathbf{x}_{t-1} - \sqrt{\overline{\alpha}_{t-1}}\mathbf{x}_0)^2}{1 - \overline{\alpha}_{t-1}} - \frac{(\mathbf{x}_t - \sqrt{\overline{\alpha}_t}\mathbf{x}_0)^2}{1 - \overline{\alpha}_t} \right)\right) \\&amp;= \exp \left( -\frac{1}{2} \left( \frac{\mathbf{x}_t^2 - 2\sqrt{\alpha_t} \mathbf{x}_t \textcolor{blue}{\mathbf{x}_{t-1}} + \alpha_t \textcolor{red}{\mathbf{x}_{t-1}^2}}{\beta_t} + \frac{\textcolor{red}{\mathbf{x}_{t-1}^2} - 2\sqrt{\overline{\alpha}_{t-1}} \mathbf{x}_0 \textcolor{blue}{\mathbf{x}_{t-1}}  + \overline{\alpha}_{t-1}\mathbf{x}_0^2}{1 - \overline{\alpha}_{t-1}} - \frac{(\mathbf{x}_t - \sqrt{\overline{\alpha}_t} \mathbf{x}_0)^2}{1 - \overline{\alpha}_t} \right)\right) \\&amp;= \exp \left( - \frac{1}{2}\left(\textcolor{red}{ (\frac{\alpha_t}{\beta_t} + \frac{1}{1 - \overline{\alpha}_{t-1}})}\mathbf{x}_{t-1}^2 - \textcolor{blue}{(\frac{2\sqrt{\alpha_t}}{\beta_t}\mathbf{x}_t + \frac{2\sqrt{\overline{\alpha}_t - 1}}{1 - \overline{\alpha}_{t-1}} \mathbf{x}_0)} \mathbf{x}_{t-1} + C(\mathbf{x}_t, \mathbf{x}_0)    \right)\right)\end{split} \tag{11}\]</span></p><blockquote><p><strong>高斯概率密度函数</strong> <span class="math display">\[\mathcal{N}(\mu, \sigma^2) = \frac{1}{\sqrt{2 \pi \sigma}} \exp \left(-\frac{1}{2} \left( \frac{x-\mu}{\sigma}\right)^2 \right) = \frac{1}{\sqrt{2 \pi \sigma}} \exp \left(-\frac{1}{2} \left(\frac{1}{\sigma^2}x^2 - \frac{2\mu}{\sigma^2} x + \frac{\mu^2}{\sigma^2}\right)\right)\]</span></p></blockquote><p>在上面的推导过程中，我们可以看到通过贝叶斯公式将逆向过程转换为前向过程，且最终得到的概率密度函数和高斯概率密度函数的指数部分能一一对应。结合前文 <span class="math inline">\(\alpha_t + \beta_t = 1\)</span>，我们可以建立如下对应关系：</p><p><span class="math display">\[\begin{split}&amp; \frac{\alpha_t}{\beta_t} + \frac{1}{1 - \overline{\alpha}_{t-1}} = \frac{1}{\tilde{\beta}_t} \\&amp; \Rightarrow \tilde{\beta}_t = \frac{1}{\frac{\alpha_t}{\beta_t} + \frac{1}{1 - \overline{\alpha}_{t-1}}} = \frac{1}{\frac{\alpha_t - \overline{\alpha}_t + \beta_t}{\beta_t(1-\overline{\alpha}_{t-1})}} \\&amp; = \frac{\beta_t(1-\overline{\alpha}_{t-1})}{\alpha_t - \overline{\alpha}_t + \beta_t} = \frac{1 - \overline{\alpha}_{t-1}}{1 - \overline{\alpha}_t} \beta_t\end{split}\tag{12}\]</span></p><p><span class="math display">\[\begin{split}&amp;\frac{2\sqrt{\alpha_t}}{\beta_t}\mathbf{x}_t + \frac{2\sqrt{\overline{\alpha}_t - 1}}{1 - \overline{\alpha}_{t-1}} \mathbf{x}_0 = \frac{2 \tilde{\mu}_t(\mathbf{x}_t, \mathbf{x}_0)}{\tilde{\beta}_t} \\&amp; \Rightarrow \tilde{\mu}_t(\mathbf{x}_t, \mathbf{x}_0) = \left( \frac{\sqrt{\alpha_t}}{\beta_t}\mathbf{x}_t + \frac{\sqrt{\overline{\alpha}_t - 1}}{1 - \overline{\alpha}_{t-1}} \mathbf{x}_0 \right) \tilde{\beta}_t \\&amp;= \left( \frac{\sqrt{\alpha_t}}{\beta_t}\mathbf{x}_t + \frac{\sqrt{\overline{\alpha}_t - 1}}{1 - \overline{\alpha}_{t-1}} \mathbf{x}_0 \right) \frac{1 - \overline{\alpha}_{t-1}}{1 - \overline{\alpha}_t} \beta_t \\&amp;= \frac{(1-\overline{\alpha}_{t-1})\sqrt{\alpha_t} \mathbf{x}_t + \beta_t \sqrt{\overline{\alpha}_{t-1}}\mathbf{x}_0}{\beta_t (1-\overline{\alpha}_{t-1})} \cdot \frac{(1 - \overline{\alpha}_{t-1})\beta_t }{1 - \overline{\alpha}_t} \\&amp;= \frac{\sqrt{\alpha_t}(1-\overline{\alpha}_{t-1})}{1-\overline{\alpha}_t} \mathbf{x}_t + \frac{\sqrt{\overline{\alpha}_{t-1}}\beta_t}{1-\overline{\alpha}_t} \mathbf{x}_0\end{split}\tag{13}\]</span></p><h3 id="求解均值-mu_thetamathbfx_t-mathbfx_0-和方差-sigma_thetamathbfx_t-mathbfx_0">求解均值 <span class="math inline">\(\mu_\theta(\mathbf{x}_t, \mathbf{x}_0)\)</span> 和方差 <span class="math inline">\(\Sigma_\theta(\mathbf{x}_t, \mathbf{x}_0)\)</span></h3><p>通过公式（10）和（11），我们可以得到 <span class="math inline">\(q(\mathbf{x}_{t-1}|\mathbf{x}_t, \mathbf{x}_0)\)</span> 的分布。而且，根据公式（3）<span class="math inline">\(\mathbf{x}_t = \sqrt{\overline{\alpha}_t}\mathbf{x}_0 + \sqrt{1-\overline{\alpha_t}}\tilde{\epsilon}_t\)</span>，可以得到： <span class="math display">\[\mathbf{x}_0 = \frac{1}{\sqrt{\overline{\alpha}_t}}(\mathbf{x}_t - \sqrt{1-\overline{\alpha}_t} \tilde{\epsilon}_t) \tag{14}\]</span></p><p>将公式（14）代入公式（13），可以得到如下结果： <span class="math display">\[\begin{split}\tilde{\mu}_t(\mathbf{x}_t, \mathbf{x}_0) &amp;= \frac{\sqrt{\alpha_t}(1-\overline{\alpha}_{t-1})}{1-\overline{\alpha}_t} \mathbf{x}_t + \frac{\sqrt{\overline{\alpha}_{t-1}}\beta_t}{1-\overline{\alpha}_t} \mathbf{x}_0 \\&amp;= \frac{\sqrt{\alpha_t}(1-\overline{\alpha}_{t-1})}{1-\overline{\alpha}_t} \mathbf{x}_t + \frac{\sqrt{\overline{\alpha}_{t-1}}\beta_t}{1-\overline{\alpha}_t} \frac{1}{\sqrt{\overline{\alpha}_t}}(\mathbf{x}_t - \sqrt{1-\overline{\alpha}_t} \tilde{\epsilon}_t) \\&amp;= \frac{\alpha_t(1-\overline{\alpha}_{t-1})\mathbf{x}_t}{\sqrt{\alpha_t}(1-\overline{\alpha}_t)} + \frac{\beta_t}{\sqrt{\alpha_t}(1-\overline{\alpha}_t)}(\mathbf{x}_t - \sqrt{1-\overline{\alpha}_t}\epsilon_t)\\&amp;= \frac{\alpha_t \mathbf{x}_t - \overline{\alpha}_t\mathbf{x}_t + (1-\alpha_t)\mathbf{x}_t - (1-\alpha_t)\sqrt{1-\overline{\alpha}_t}\epsilon_t}{\sqrt{\alpha_t}(1-\overline{\alpha}_t)} \\&amp;= \frac{(1-\overline{\alpha}_t)\mathbf{x}_t - (1-\alpha_t)\sqrt{1-\overline{\alpha}_t}\epsilon_t}{\sqrt{\alpha_t}(1-\overline{\alpha}_t)}\\&amp;= \frac{\mathbf{x}_t}{\sqrt{\alpha_t}} - \frac{(1-\alpha_t)\epsilon_t}{\sqrt{\alpha_t}\sqrt{1-\overline{\alpha}_t}}\\&amp;= \frac{1}{\sqrt{\alpha_t}}\left(\mathbf{x}_t - \frac{1-\alpha_t}{\sqrt{1-\overline{\alpha}_t}} \epsilon_t \right)\end{split}\tag{15}\]</span></p><p>之前说到，我们使用深度学习模型 <span class="math inline">\(p_\theta\)</span> 去拟合逆向过程的分布 <span class="math inline">\(q(\mathbf{x}_{t-1}|\mathbf{x}_t)\)</span>， 根据公式（9）可知，<span class="math inline">\(p_\theta(\mathbf{x}_{t-1}|\mathbf{x}_t) = \mathcal{N}(\mathbf{x}_{t-1};\mu_\theta(\mathbf{x}_t, t), \Sigma_\theta(\mathbf{x}_t, t))\)</span>，我们希望训练模型 <span class="math inline">\(\mu_\theta(\mathbf{x}_t, t)\)</span> 以预估 <span class="math inline">\(\tilde{\mu}_t = \frac{1}{\sqrt{\alpha_t}}\left(\mathbf{x}_t - \frac{1-\alpha_t}{\sqrt{1-\overline{\alpha}_t}} \epsilon_t \right)\)</span>。由于 <span class="math inline">\(\mathbf{x}_t\)</span> 在训练阶段的逆向过程中是输入的图片数据，因此是已知的，我们可以转而让模型去预估噪声 <span class="math inline">\(\epsilon_t\)</span>， 即令：</p><p><span class="math display">\[\mu_\theta (\mathbf{x}_t, t) = \frac{1}{\sqrt{\alpha_t}}\left(\mathbf{x}_t - \frac{1-\alpha_t}{\sqrt{1-\overline{\alpha}_t}} \epsilon_\theta(\mathbf{x}_t, t) \right) \tag{16}\]</span></p><p>因此，</p><p><span class="math display">\[ \mathbf{x}_{t-1} = \mathcal{N}(\mathbf{x}_{t-1}; \frac{1}{\sqrt{\alpha_t}}\left(\mathbf{x}_t - \frac{1-\alpha_t}{\sqrt{1-\overline{\alpha}_t}} \epsilon_\theta(\mathbf{x}_t, t) \right), \Sigma_\theta(\mathbf{x}_t, t) ) \tag{17}\]</span></p><p>方差 <span class="math inline">\(\Sigma_\theta(\mathbf{x}_t, t)\)</span> 可以有多种选择，DDPM使用的是 <span class="math inline">\(\Sigma_\theta(\mathbf{x}_t, t) = \tilde{\beta}_t\)</span> 且认为 <span class="math inline">\(\tilde{\beta}_t = \beta_t\)</span> 和 <span class="math inline">\(\tilde{\beta}_t = \frac{1 - \overline{\alpha}_{t-1}}{1 - \overline{\alpha}_t} \cdot \beta_t\)</span> 的结果近似，而在<a href="https://arxiv.org/abs/2112.10741">GLIDE</a>中，则是根据网络预测的结果计算方差。</p><h3 id="ddpm-推断过程">DDPM 推断过程</h3><p>因此，DDPM每一步推断可以总结如下：</p><ul><li>每个时间步骤通过 <span class="math inline">\(\mathbf{x}_t\)</span> 和步骤 <span class="math inline">\(t\)</span> 来预测高斯噪声 <span class="math inline">\(\epsilon_\theta(\mathbf{x}_t, t)\)</span>，然后根据公式（16）得到均值 <span class="math inline">\(\mu_\theta(\mathbf{x}_t, t)\)</span></li><li>得到方差 <span class="math inline">\(\Sigma_\theta(\mathbf{x}_t, t)\)</span>， DDPM使用的是 <span class="math inline">\(\Sigma_\theta(\mathbf{x}_t, t) = \tilde{\beta}_t\)</span> 且认为 <span class="math inline">\(\tilde{\beta}_t = \beta_t\)</span> 和 <span class="math inline">\(\tilde{\beta}_t = \frac{1 - \overline{\alpha}_{t-1}}{1 - \overline{\alpha}_t} \cdot \beta_t\)</span> 的结果近似，</li><li>根据公式（9）得到 <span class="math inline">\(q(\mathbf{x}_{t-1}|\mathbf{x}_t)\)</span>，利用重参数得到 <span class="math inline">\(\mathbf{x}_{t-1}\)</span></li></ul><figure><img src="/2022/10/29/DDPM/DDPM_Forw_Rev.png" alt="图2 DDDPM前向与逆向数据转换过程，可以看到逆向过程中 \mathbf{x}_0 和 \mathbf{x}_t 之间反复横跳"><figcaption aria-hidden="true">图2 DDDPM前向与逆向数据转换过程，可以看到逆向过程中 <span class="math inline">\(\mathbf{x}_0\)</span> 和 <span class="math inline">\(\mathbf{x}_t\)</span> 之间反复横跳</figcaption></figure><h2 id="diffusion-模型训练">Diffusion 模型训练</h2><p>逆向阶段是让模型去预估噪声 <span class="math inline">\(\epsilon_\theta(\mathbf{x}_t, t)\)</span>，从而产生较好的 <span class="math inline">\(\mu_\theta(\mathbf{x}_t, t)\)</span> 和 <span class="math inline">\(\Sigma_\theta(\mathbf{x}_t, t)\)</span>， 以求得概率 <span class="math inline">\(q(\mathbf{x}_{t-1}|\mathbf{x}_t)\)</span>。 作者的目标是在真实数据分布下，最大化模型预测分布的对数似然函数，即优化 <span class="math inline">\(\mathcal{x}_0 \sim q(\mathcal{x}_0)\)</span> 下的 <span class="math inline">\(p_\theta(\mathcal{x}_0)\)</span> 的交叉熵。</p><p><span class="math display">\[\mathcal{L} =\mathbb{E}_{q(\mathbf{x}_0)} \left[ -\log p_\theta(\mathcal{x}_0) \right] \tag{18} \]</span></p><p>和变分自动编码器类似，使用变分下限（Variantional Lower Bound, VLB）也称ELBO（Evidence Lower Bound），来优化 <span class="math inline">\(-\log p_\theta(\mathbf{x}_0)\)</span>：</p><p><span class="math display">\[\begin{split}-\log p_\theta(\mathbf{x}_0) &amp;\le -\log p_\theta(\mathbf{x}_0) + KL(q(\mathbf{x}_{1:T}|\mathbf{x}_0)||p_\theta(\mathbf{x}_{1:T}|\mathbf{x}_0)) \\&amp;= -\log p_\theta(\mathbf{x}_0) + \mathbb{E}_{q(\mathbf{x}_{1:T}|\mathbf{x}_0)} \left[\log \frac{q(\mathbf{x}_{1:T}|\mathbf{x}_0)}{p_\theta(\mathbf{x}_{1:T}|\mathbf{x}_0)}\right] \\&amp;= -\log p_\theta(\mathbf{x}_0) + \mathbb{E}_{q(\mathbf{x}_{1:T}|\mathbf{x}_0)} \left[\log \frac{q(\mathbf{x}_{1:T}|\mathbf{x}_0)}{p_\theta(\mathbf{x}_{0:T})/p_\theta(\mathbf{x}_0)}\right] \\&amp;= -\log p_\theta(\mathbf{x}_0) + \mathbb{E}_{q(\mathbf{x}_{1:T}|\mathbf{x}_0)} \left[\log \frac{q(\mathbf{x}_{1:T}|\mathbf{x}_0)}{p_\theta(\mathbf{x}_{0:T})} + \underbrace{\log p_\theta(\mathbf{x}_0)}_{与q无关}\right] \\&amp;= \mathbb{E}_{q(\mathbf{x}_{1:T}|\mathbf{x}_0)} \left[\log \frac{q(\mathbf{x}_{1:T}|\mathbf{x}_0)}{p_\theta(\mathbf{x}_{0:T})} \right] \\\end{split}\tag{19}\]</span></p><blockquote><p><strong>KL散度</strong> <span class="math display">\[KL(P||Q) = \sum_i P(x_i) \log \frac{P(x_i)}{Q(x_i)}\]</span></p><p><strong>Fubini定理</strong></p><p>如果 <span class="math inline">\(\int_{A\times B} |f(x,y)| d(x,y) &lt; \infty\)</span>, 则下式成立 <span class="math display">\[\int_A \left(\int_B f(x,y) dy\right)dx = \int_B \left(\int_A f(x,y) dx\right)dy = \int_{A\times B} f(x,y) d(x,y)\]</span></p></blockquote><h3 id="fubini定理推断mathcall_vlb">Fubini定理推断<span class="math inline">\(\mathcal{L}_{VLB}\)</span></h3><p>根据公式（18），对公式（19）左右两边取期望 <span class="math inline">\(\mathbb{E}_{q(\mathbf{x}_0)}\)</span>，利用重积分中的Fubini定理： <span class="math display">\[\begin{split}\mathcal{L}_{VLB} &amp;= \mathbb{E}_{q(\mathbf{x}_0)}\left( \mathbb{E}_{q(\mathbf{x}_{1:T}|\mathbf{x}_0)} \left[\log \frac{q(\mathbf{x}_{1:T}|\mathbf{x}_0)}{p_\theta(\mathbf{x}_{0:T})} \right]  \right) = \mathbb{E}_{q(\mathbf{x_{0:T}})} \left[ \log \frac{q(\mathbf{x}_{1:T}|\mathbf{x}_0)}{p_\theta(\mathbf{x}_{0:T})}  \right] \\&amp; \ge \mathbb{E}_{q(\mathbf{x}_0)} \left[ -\log p_\theta(\mathcal{x}_0) \right]\end{split}\tag{20}\]</span></p><p>最小化 <span class="math inline">\(\mathcal{L}_{VLB}\)</span> 即可最小化我们的目标损失函数，即公式（18）。</p><h3 id="jensen不等式推断mathcall_vlb">Jensen不等式推断<span class="math inline">\(\mathcal{L}_{VLB}\)</span></h3><blockquote><p><strong>Jensen不等式概率论版本</strong></p><p>对于随机变量<span class="math inline">\(X\)</span>，<span class="math inline">\(\varphi\)</span> 是任意凸函数，则下式成立 <span class="math display">\[\varphi(E(X)) \le E(\varphi(X))\]</span></p></blockquote><p><span class="math display">\[\begin{split}\mathcal{L} &amp;= \mathbb{E}_{q(\mathbf{x}_0)} \left[ -\log p_\theta(\mathcal{x}_0) \right] \\&amp;= - \mathbb{E}_{q(\mathbf{x}_0)} \log \left( p_\theta(\mathbf{x}_0) \cdot \int p_\theta(\mathbf{x}_{1:T}) d\mathbf{x}_{1:T} \right) \\&amp;= - \mathbb{E}_{q(\mathbf{x}_0)}\log\left( \int p_\theta(\mathbf{x}_{0:T})d\mathbf{x}_{1:T} \right)\\&amp;= - \mathbb{E}_{q(\mathbf{x}_0)}\log\left( \int q(\mathbf{x}_{1:T}|\mathbf{x}_0) \frac{p_\theta(\mathbf{x}_{0:T})}{q(\mathbf{x}_{1:T}|\mathbf{x}_0)} d\mathbf{x}_{1:T} \right)\\&amp;= - \mathbb{E}_{q(\mathbf{x}_0)}\log\left( \mathbb{E}_{q(\mathbf{x}_{1:T}|\mathbf{x}_0)} \frac{p_\theta(\mathbf{x}_{0:T})}{q(\mathbf{x}_{1:T}|\mathbf{x}_0)} \right)\\&amp;= \mathbb{E}_{q(\mathbf{x}_0)}\log\left( \mathbb{E}_{q(\mathbf{x}_{1:T}|\mathbf{x}_0)} \frac{q(\mathbf{x}_{1:T}|\mathbf{x}_0)}{p_\theta(\mathbf{x}_{0:T})} \right)\\&amp;\le \mathbb{E}_{q(\mathbf{x}_{0:T})} \log \frac{q(\mathbf{x}_{1:T}|\mathbf{x}_0)}{p_\theta(\mathbf{x}_{0:T})} = \mathcal{L}_{VLB}\end{split} \tag{21}\]</span></p><p>可以看到，通过Fubini定理和Jensen不等式都可以得到相同的结果。这里需要解释下公式（21）中几个步骤。</p><ul><li>第2行到第3行：因为 <span class="math inline">\(p_\theta(\mathbf{x}_0)\)</span> 和 <span class="math inline">\(\mathbf{x}_{1:T}\)</span> 无关，因此可以将 <span class="math inline">\(p_\theta(\mathbf{x}_0)\)</span> 看作常数项与 <span class="math inline">\(p_\theta(\mathbf{x}_{1:T})\)</span> 相乘。根据联合概率密度函数定义，我们可以看出 <span class="math inline">\(p_\theta(\mathbf{x}_{0:T}) = p_\theta(\mathbf{x}_0) p_\theta(\mathbf{x}_{1:T})\)</span></li><li>第6行到第7行：将 <span class="math inline">\(\log\)</span> 函数看作 <span class="math inline">\(\varphi\)</span>，根据Jensen不等式可知不等号成立。且根据 <span class="math inline">\(p_\theta(\mathbf{x}_{0:T}) = p_\theta(\mathbf{x}_0) p_\theta(\mathbf{x}_{1:T})\)</span>，我们可以看出，对 <span class="math inline">\(q(\mathbf{x}_0)\)</span> 和 <span class="math inline">\(q(\mathbf{x}_{1:T}|\mathbf{x}_0)\)</span> 连续积分可以得到 <span class="math inline">\(q(\mathbf{x}_{0:T})\)</span></li></ul><h3 id="进一步拆解-_vlb">进一步拆解 $_{VLB} $</h3><p>进一步对 <span class="math inline">\(\mathcal{L}_{VLB}\)</span> 推导，可以得到熵与多个KL散度的累加，具体推导如下：</p><p><span class="math display">\[\begin{split}\mathcal{L}_{VLB} &amp;= \mathbb{E}_{q(\mathbf{x}_{0:T})} \left[ \log \frac{q(\mathcal{x}_{1:T}|\mathcal{x}_0)}{p_\theta(\mathcal{x}_{0:T})} \right]\\&amp;= \mathbb{E}_{q(\mathbf{x}_{0:T})} \left[ \log \frac{\prod^T_{t=1} q(\mathbf{x}_t|\mathbf{x}_{t-1})}{p_\theta(\mathbf{x}_T)\prod^T_{t=1}p_\theta(\mathbf{x}_{t-1}|\mathbf{x}_t)} \right]\\&amp;= \mathbb{E}_{q(\mathbf{x}_{0:T})} \left[ - \log p_\theta(\mathbf{x}_T) + \sum^T_{t=1} \log \frac{q(\mathbf{x}_t|\mathbf{x}_{t-1})}{p_\theta(\mathbf{x}_{t-1}|\mathbf{x}_t)} \right]\\&amp;= \mathbb{E}_{q(\mathbf{x}_{0:T})} \left[ - \log p_\theta(\mathbf{x}_T) + \sum^T_{t=2} \log \frac{q(\mathbf{x}_t|\mathbf{x}_{t-1})}{p_\theta(\mathbf{x}_{t-1}|\mathbf{x}_t)} + \log \frac{q(\mathbf{x}_1|\mathbf{x}_0)}{p_\theta(\mathbf{x}_0|\mathbf{x}_1)} \right]\\&amp;= \mathbb{E}_{q(\mathbf{x}_{0:T})} \left[ - \log p_\theta(\mathbf{x}_T) + \sum^T_{t=2} \log \left( \frac{q(\mathbf{x}_t|\mathbf{x}_t, \mathbf{x}_0)}{p_\theta(\mathbf{x}_{t-1}|\mathbf{x}_t)} \cdot \frac{q(\mathbf{x}_t|\mathbf{x}_0)}{q(\mathbf{x}_{t-1}|\mathbf{x}_0)} \right) + \log \frac{q(\mathbf{x}_1|\mathbf{x}_0)}{p_\theta(\mathbf{x}_0|\mathbf{x}_1)} \right]\\&amp;= \mathbb{E}_{q(\mathbf{x}_{0:T})} \left[ - \log p_\theta(\mathbf{x}_T) + \sum^T_{t=2} \log \frac{q(\mathbf{x}_t|\mathbf{x}_t, \mathbf{x}_0)}{p_\theta(\mathbf{x}_{t-1}|\mathbf{x}_t)} + \sum^T_{t=2} \log \frac{q(\mathbf{x}_t|\mathbf{x}_0)}{q(\mathbf{x}_{t-1}|\mathbf{x}_0)} + \log \frac{q(\mathbf{x}_1|\mathbf{x}_0)}{p_\theta(\mathbf{x}_0|\mathbf{x}_1)} \right]\\&amp;= \mathbb{E}_{q(\mathbf{x}_{0:T})} \left[ - \log p_\theta(\mathbf{x}_T) + \sum^T_{t=2} \log \frac{q(\mathbf{x}_t|\mathbf{x}_t, \mathbf{x}_0)}{p_\theta(\mathbf{x}_{t-1}|\mathbf{x}_t)} + \log \frac{q(\mathbf{x}_T|\mathbf{x}_0)}{q(\mathbf{x}_{1}|\mathbf{x}_0)} + \log \frac{q(\mathbf{x}_1|\mathbf{x}_0)}{p_\theta(\mathbf{x}_0|\mathbf{x}_1)} \right]\\&amp;= \mathbb{E}_{q(\mathbf{x}_{0:T})} \left[ - \log p_\theta(\mathbf{x}_T) + \sum^T_{t=2} \log \frac{q(\mathbf{x}_t|\mathbf{x}_t, \mathbf{x}_0)}{p_\theta(\mathbf{x}_{t-1}|\mathbf{x}_t)}  + \log q(\mathbf{x}_1|\mathbf{x}_0) - \log p_\theta(\mathbf{x}_0|\mathbf{x}_1) \right] \\&amp;= \mathbb{E}_{q(\mathbf{x}_{0:T})} \left[ \log \frac{q(\mathbf{x}_T|\mathbf{x}_0)}{p_\theta(\mathbf{x}_T)} + \sum^T_{t=2} \log \frac{q(\mathbf{x}_t|\mathbf{x}_t, \mathbf{x}_0)}{p_\theta(\mathbf{x}_{t-1}|\mathbf{x}_t)} - \log p_\theta(\mathbf{x}_0|\mathbf{x}_1) \right]\\&amp;= \mathbb{E}_{q(\mathbf{x}_{0:T})} \left[ \underbrace{KL(q(\mathbf{x}_T|\mathbf{x}_0)||p_\theta(\mathbf{x}_T))}_{L_T} + \sum^T_{t=2} \underbrace{KL(q(\mathbf{x}_{t-1}|\mathbf{x}_t, \mathbf{x}_0)||p_\theta(\mathbf{x}_{t-1}|\mathbf{x}_t))}_{L_{t-1}} - \underbrace{\log p_\theta(\mathbf{x}_0|\mathbf{x}_1)}_{L_0} \right]\end{split}\tag{22}\]</span></p><p>公式（22）的解释： + 第1行到第2行：分子是根据公式（1）得来。分母是根据公式（8）得来 + 第4行到第5行：我们可以看到，第四行中 <span class="math inline">\(\log\)</span> 符号后分式中分母保持不变，只是分子 <span class="math inline">\(q(\mathbf{x}_t|\mathbf{x}_{t-1})\)</span> 通过贝叶斯公式转换： <span class="math display">\[q(\mathbf{x}_t|\mathbf{x}_{t-1}) = \frac{q(\mathbf{x}_t, \mathbf{x}_{t-1}|\mathbf{x}_0)}{q(\mathbf{x}_{t-1}|\mathbf{x}_0)} = \frac{q(\mathbf{x}_{t-1}|\mathbf{x}_{t},\mathbf{x}_0) \cdot p(\mathbf{x}_{t}|\mathbf{x}_0)}{q(\mathbf{x}_{t-1}|\mathbf{x}_0)} \]</span></p><p>公式（22）可以重新写为以下公式： <span class="math display">\[\mathcal{L}_{VLB} = L_T + L_{T-1} + \cdots + L_0 \tag{23-1}\]</span> <span class="math display">\[L_T = KL(q(\mathbf{x}_T|\mathbf{x}_0)||p_\theta(\mathbf{x}_T)) \tag{23-2}\]</span> <span class="math display">\[L_t = KL(q(\mathbf{x}_{t-1}|\mathbf{x}_t, \mathbf{x}_0)||p_\theta(\mathbf{x}_{t-1}|\mathbf{x}_t)); \quad 1 \le t \le T-1 \tag{23-3}\]</span> <span class="math display">\[L_0 = - \log p_\theta(\mathbf{x}_0|\mathbf{x}_1) \tag{23-4}\]</span></p><h3 id="ddpm的loss">DDPM的LOSS</h3><p>由于前向过程 <span class="math inline">\(q\)</span> 没有可学习的参数，而且 <span class="math inline">\(\mathcal{x}_T\)</span> 是纯高斯噪声，因此公式（23-2）中的 <span class="math inline">\(L_T\)</span> 可以当作常量忽略。最后一项 <span class="math inline">\(L_0\)</span> 作者使用离散分段累计函数来计算，可以避免计算协方差等过程，但该项对最终结果影响不大。 <span class="math inline">\(L_t\)</span> 可以看作是拉近两个变量的高斯分布，即公式（10）<span class="math inline">\(q(\mathbf{x}_{t-1}|\mathbf{x}_t, \mathbf{x}_0) = \mathcal{N}(\mathbf{x}_{t-1}; \textcolor{blue}{\tilde{\mu_t}} (\mathbf{x}_t, \mathbf{x}_0), \textcolor{red} {\tilde{\beta_t}} \mathbb{I})\)</span> 和公式（9）<span class="math inline">\(p_\theta(\mathbf{x}_{t-1}|\mathbf{x}_t) = \mathcal{N}(\mathbf{x}_{t-1};\mu_\theta(\mathbf{x}_t, t), \Sigma_\theta(\mathbf{x}_t, t))\)</span>，根据<a href="https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence#Multivariate_normal_distributions">多元高斯分布的KL散度求解</a>，可以得到下式： <span class="math display">\[L_t = \mathbb{E}_{q(\mathbf{x}_{0:T})}\left[\frac{1}{2||\Sigma_\theta(\mathbf{x}_t, \mathbf{x}_0)||_2^2}||\tilde{\mu}(\mathbf{x}_t, \mathbf{x}_0) - \mu_\theta(\mathbf{x}_t, t)||^2 \right]+C_t \tag{24}\]</span></p><blockquote><p><strong>多元高斯分布KL散度解释</strong></p><p><span class="math display">\[KL(p||q) = \frac{(\mu_1 - \mu_2)^2}{2 \sigma_2^2} + \frac{\sigma_1^2}{2\sigma_2^2} + \log \frac{\sigma_2}{\sigma_p} - \frac{1}{2} \]</span> 由于DDPM中只有均值是与参数 <span class="math inline">\(\theta\)</span> 相关，因此，这里后三项都是与参数 <span class="math inline">\(\theta\)</span> 无关的常数。</p></blockquote><p>其中公式（24）中参数 <span class="math inline">\(C\)</span> 是与模型参数 <span class="math inline">\(\theta\)</span> 无关的常量。将公式（15）和公式（16）的结果代入公式（24）可以得到： <span class="math display">\[\begin{split}L_t &amp;= \mathbb{E}_{\mathbf{x}_0, \epsilon}\left[\frac{1}{2||\Sigma_\theta(\mathbf{x}_t, \mathbf{x}_0)||_2^2}||\tilde{\mu}(\mathbf{x}_t, \mathbf{x}_0) - \mu_\theta(\mathbf{x}_t, t)||^2 \right]\\ &amp;= \mathbb{E}_{\mathbf{x}_0, \epsilon}\left[\frac{1}{2||\Sigma_\theta||_2^2}\left|\left|\frac{1}{\sqrt{\alpha_t}}\left(\mathbf{x}_t - \frac{1-\alpha_t}{\sqrt{1-\overline{\alpha}_t}} \epsilon_t \right) - \frac{1}{\sqrt{\alpha_t}}\left(\mathbf{x}_t - \frac{1-\alpha_t}{\sqrt{1-\overline{\alpha}_t}} \epsilon_\theta(\mathbf{x}_t, t) \right)\right|\right|^2 \right]\\&amp;= \mathbb{E}_{\mathbf{x}_0, \epsilon} \left[ \frac{1}{2||\Sigma_\theta||_2^2} \left|\left| \frac{1}{\sqrt{\overline{\alpha}_t}} \frac{1-\alpha_t}{\sqrt{1-\overline{\alpha}_t}} (\epsilon_t - \epsilon_\theta(\mathbf{x}_t, t)) \right|\right|^2\right] \\&amp;= \mathbb{E}_{\mathbf{x}_0, \epsilon} \left[ \frac{(1-\alpha_t)^2}{2 \alpha_t (1-\overline{\alpha}_t) ||\Sigma_\theta||^2_2} ||\epsilon_t - \epsilon_\theta(\mathbf{x}_t, t)||^2 \right] \\&amp;= \mathbb{E}_{\mathbf{x}_0, \epsilon} \left[ \frac{(1-\alpha_t)^2}{2 \alpha_t (1-\overline{\alpha}_t) ||\Sigma_\theta||^2_2} ||\epsilon_t - \epsilon_\theta(\sqrt{\overline{\alpha}_t} \mathbf{x}_0 + \sqrt{1-\overline{\alpha}_t} \tilde{\epsilon_t}, t)||^2 \right] \\\end{split}\tag{25}\]</span></p><p>公式（25）中最后一行是根据公式（3）将 <span class="math inline">\(\mathbf{x}_t\)</span> 替换为 <span class="math inline">\(\mathbf{x}_0\)</span>。因此DDPM的Loss狠心是学习高斯噪声 <span class="math inline">\(\epsilon_t\)</span> 和 <span class="math inline">\(\epsilon_\theta\)</span> 之间的MSE。</p><h2 id="ddpm最终算法">DDPM最终算法</h2><p>DDPM最终算法流程如下，其中Training表示训练阶段，Sampling表示逆向阶段。根据代码理解，Train完成之后，通过Sampling生成图像。 <img src="/2022/10/29/DDPM/DDPM_Total_Alg.png" alt="DDPM最终算法"></p><p><strong>训练阶段的步骤：</strong></p><ul><li><p>从数据集中采样 <span class="math inline">\(\mathbf{x}_0\)</span></p></li><li><p>随机选取时间步骤<span class="math inline">\(t\)</span></p></li><li><p>生成高斯噪声 <span class="math inline">\(\epsilon_t \in \mathcal{N}(0, \mathbb{I})\)</span></p></li><li><p>预估 <span class="math inline">\(\epsilon_\theta(\sqrt{\overline{\alpha}_t} \mathbf{x}_0 + \sqrt{1-\overline{\alpha}_t} \tilde{\epsilon_t}, t)\)</span></p></li><li><p>计算MSE Loss: <span class="math inline">\(||\epsilon_t - \epsilon_\theta(\sqrt{\overline{\alpha}_t} \mathbf{x}_0 + \sqrt{1-\overline{\alpha}_t} \tilde{\epsilon_t}, t)||^2\)</span>，并利用反向传播算法训练模型</p></li></ul><p><strong>逆向阶段采用如下步骤进行采样：</strong></p><ul><li><p>从高斯分布中采样 <span class="math inline">\(\mathcal{x}_T\)</span></p></li><li><p>按照 <span class="math inline">\(T,T-1,\cdots,1\)</span>的顺序进行迭代</p><ul><li><p>如果 <span class="math inline">\(t\)</span> = 1，令 <span class="math inline">\(z=0\)</span>；如果 <span class="math inline">\(t&gt;1\)</span>，则从高斯分布中采样 <span class="math inline">\(z\sim\mathcal{N}(0, \mathbb{I})\)</span></p></li><li><p>利用公式（16）学习出均值 <span class="math inline">\(\mu_\theta(\mathbf{x}_t, t)\)</span>，并利用公式（12）计算方差 <span class="math inline">\(\sigma_t\)</span></p></li><li><p>通过重参数技巧采样 <span class="math inline">\(\mathbf{x}_{t-1} = \mu_\theta(\mathbf{x}_t, t) + \sigma_t z\)</span></p></li></ul></li><li><p>通过以上步骤恢复出 <span class="math inline">\(\mathbf{x}_0\)</span></p></li></ul><h1 id="代码解读">代码解读</h1><p>Coming soon</p><h1 id="ddim加速diffusion采样和方差的选择">DDIM：加速Diffusion采样和方差的选择</h1><p>DDPM的高质量生成依赖较大的 <span class="math inline">\(T\)</span>, 这就导致Diffusion的前向过程非常缓慢，因此有作者提出一种牺牲多样性来换取更快推断的手段，提出了 <a href="https://arxiv.org/abs/2010.02502">Denoising diffusion implicit model (DDIM)</a>。</p><p>根据公式（3）及高斯分布可加性，可以得到 <span class="math inline">\(\mathbf{x}_{t-1}\)</span> 为： <span class="math display">\[\begin{split}\mathbf{x}_{t-1} &amp;= \sqrt{\overline{\alpha}_{t-1}} \mathbf{x}_0 + \sqrt{1 - \overline{\alpha}_{t-1}} \tilde{\epsilon}_{t-1} \\&amp;= \sqrt{\overline{\alpha}_{t-1}} \mathbf{x}_0 + \sqrt{1-\overline{\alpha}_{t-1}-\sigma^2_t}\tilde{\epsilon}_t + \sigma_t \epsilon_t \\&amp;= \sqrt{\overline{\alpha}_{t-1}} \mathbf{x}_0 + \sqrt{1 - \overline{\alpha}_{t-1} - \sigma^2_t} \left( \frac{\mathbf{x}_t - \sqrt{\overline{\alpha}_t}\mathbf{x}_0}{\sqrt{1-\overline{\alpha}_t}} \right) + \sigma_t \epsilon_t\end{split}\tag{26}\]</span></p><p>根据上文，我们可以得知 <span class="math inline">\(\epsilon_t \sim \mathcal{N}(0,1)\)</span> 是服从标准正态分布的噪声, <span class="math inline">\(\tilde{\epsilon}_t \sim \mathcal{N}(0,1)\)</span> 是根据正态分布可加性变换过的且服从标准正态分布的噪声。 公式（26）第二行是根据高斯分布可加性推导而来， 假定 $P_A =  <em>{t-1} (0, (1-</em>{t-1}) ) <span class="math inline">\(，\)</span>P_B = (0, _t^2) $，我们可以得到如下推断： <span class="math display">\[\begin{split}P_A &amp;= P_A - P_B + P_B\\&amp;= \sqrt{\overline{\alpha}_{t-1}} \mathbf{x}_0 + \sqrt{1-\overline{\alpha}_{t-1}-\sigma^2_t}\tilde{\epsilon}_t + \sigma_t \epsilon_t \\\end{split}\tag{27}\]</span> 公式（26）第二行到第三行也是根据公式（3）变换而来： <span class="math display">\[\begin{split}&amp; \mathbf{x}_{t} = \sqrt{\overline{\alpha}_{t}} \mathbf{x}_0 + \sqrt{1 - \overline{\alpha}_{t}} \tilde{\epsilon}_{t} \\ &amp; \Rightarrow \tilde{\epsilon}_t = \frac{\mathbf{x}_t - \sqrt{\overline{\alpha}_t}\mathbf{x}_0}{\sqrt{1-\overline{\alpha}_t}}\end{split}\tag{28}\]</span> 因此可以重写公式（10）和（11）为 <span class="math display">\[q_\sigma (\mathbf{x}_{t-1}|\mathbf{x}_t, \mathbf{x}_0) = \mathcal{N}(\mathbf{x}_{t-1}; \sqrt{\overline{\alpha}_{t-1}} \mathbf{x}_0 + \sqrt{1 - \overline{\alpha}_{t-1} - \sigma^2_t} \left( \frac{\mathbf{x}_t - \sqrt{\overline{\alpha}_t}\mathbf{x}_0}{\sqrt{1-\overline{\alpha}_t}} \right), \sigma_t^2 \mathbb{I}) \tag{29}\]</span></p><p>不同于公式（10）和（16），公式（26）将方差 <span class="math inline">\(\sigma_t^2\)</span> 引入到了均值当中，当 <span class="math inline">\(\sigma_t^2 = \tilde{\beta}_t = \frac{1-\overline{\alpha}_{t-1}}{1-\overline{\alpha}_t} \beta_t\)</span> 时，公式（26）等价于公式（10）。 在DDIM中将由公式（26）得到的 <span class="math inline">\(q_\sigma (\mathbf{x}_{t-1}|\mathbf{x}_t, \mathbf{x}_0)\)</span> 称为非马尔可夫过程，因为 <span class="math inline">\(\mathbf{x}_t\)</span> 的分布同时依赖 <span class="math inline">\(\mathbf{x}_{t-1}\)</span> 和 <span class="math inline">\(\mathbf{x}_0\)</span>。DDIM进一步定义了 <span class="math inline">\(\sigma_t(\eta)^2 = \eta \cdot \tilde{\beta}_t\)</span>。当 <span class="math inline">\(\eta=0\)</span> 时，diffusion的采样过程会丧失所有随机性从而得到一个确定性的结果，但是可以改变 <span class="math inline">\(\mathbf{x}_T\)</span>。而当 <span class="math inline">\(\eta = 1\)</span> 时，DDIM等驾驭DDPM （使用 <span class="math inline">\(\tilde{\beta}_t\)</span>作为方差的版本），用随机性换取生成性能。</p><p>对于方差 <span class="math inline">\(\sigma_t^2\)</span> 的选择，可以总结如下：</p><ul><li>DDPM:<ul><li><span class="math inline">\(\sigma^2_{t,\theta} = \Sigma_\theta(\mathbf{x}_t, t)\)</span> 相当于模型学习的方差，DDPM称为learned，实际没有使用，GLIDE使用了这种方差。</li><li><span class="math inline">\(\sigma^2_{t,s} = \tilde{\beta}_t = \frac{1-\overline{\alpha}_{t-1}}{1-\overline{\alpha}_t} \beta_t\)</span>，DDPM称为fixedsamll，用于CelebA-HQ数据集和LSUN。</li><li><span class="math inline">\(\sigma^2_{t,l} = \beta_t\)</span>，DDPM称之为fixedlarge，用于CIFAR10数据集，注意 <span class="math inline">\(\sigma_{t,l}&gt;\sigma_{t,s}\)</span></li></ul></li><li>DDIM:<ul><li><span class="math inline">\(\sigma_t(\eta)^2 = \eta \cdot \tilde{\beta}_t\)</span>，DDIM是在fixedsmall版本上再乘以一个系数 <span class="math inline">\(\eta\)</span>。</li></ul></li></ul><p>假设总的采样步骤是 <span class="math inline">\(T\)</span>, 采样间隔是 <span class="math inline">\(Q\)</span>，DDIM的采样步数为 <span class="math inline">\(S=T/Q\)</span>，<span class="math inline">\(S\)</span> 和 <span class="math inline">\(\eta\)</span> 的实验结果如下： <img src="/2022/10/29/DDPM/DDIM_Exp.png" alt="DDIM的实验结果"> 可以看到在 <span class="math inline">\(S\)</span> 很小的时候 <span class="math inline">\(\eta = 0\)</span> 取得了最好的结果，而当步骤 <span class="math inline">\(T\)</span> 足够大的时候，使用更大的方差 <span class="math inline">\(\sigma_t^2\)</span> 可以得到更好的结果。</p><h1 id="参考">参考</h1><ol type="1"><li><a href="https://lilianweng.github.io/posts/2021-07-11-diffusion-models/">What are Diffusion Models?</a></li><li><a href="https://zhuanlan.zhihu.com/p/525106459">由浅入深了解Diffusion Model - 知乎</a></li><li><a href="https://zhuanlan.zhihu.com/p/576475987">扩散模型（Diffusion Model）简要介绍于源码分析</a></li></ol>]]></content>
    
    
    <categories>
      
      <category>论文阅读</category>
      
    </categories>
    
    
    <tags>
      
      <tag>神经网络</tag>
      
      <tag>生成模型</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
