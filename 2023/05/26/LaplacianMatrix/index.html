

<!DOCTYPE html>
<html lang="en" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/fluid.png">
  <link rel="icon" href="/img/fluid.png">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="Huacheng Li">
  <meta name="keywords" content="">
  
    <meta name="description" content="1. 图拉普拉斯矩阵的定义 给定图 \(\mathcal{G} &#x3D; (\mathcal{V}, \mathcal{E})\)，其拉普拉斯矩阵的定义如下： \[ L &#x3D; D - A &#x3D; \begin{cases} deg(i), &amp; i&#x3D;&#x3D;j \\ -1, &amp; e_{ij} \in  \mathcal{E} \\ 0, &amp; otherwise \end{cases}\] 其中">
<meta property="og:type" content="article">
<meta property="og:title" content="LaplacianMatrix">
<meta property="og:url" content="http://watsonlee.github.io/2023/05/26/LaplacianMatrix/index.html">
<meta property="og:site_name" content="努力减肥的小李">
<meta property="og:description" content="1. 图拉普拉斯矩阵的定义 给定图 \(\mathcal{G} &#x3D; (\mathcal{V}, \mathcal{E})\)，其拉普拉斯矩阵的定义如下： \[ L &#x3D; D - A &#x3D; \begin{cases} deg(i), &amp; i&#x3D;&#x3D;j \\ -1, &amp; e_{ij} \in  \mathcal{E} \\ 0, &amp; otherwise \end{cases}\] 其中">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://watsonlee.github.io/2023/05/26/LaplacianMatrix/example_graph.png">
<meta property="og:image" content="http://watsonlee.github.io/2023/05/26/LaplacianMatrix/eigenvalue_of_diff_matrix.png">
<meta property="article:published_time" content="2023-05-26T15:06:32.000Z">
<meta property="article:modified_time" content="2023-06-12T11:22:22.076Z">
<meta property="article:author" content="Huacheng Li">
<meta property="article:tag" content="拉普拉斯矩阵">
<meta property="article:tag" content="图正则化">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="http://watsonlee.github.io/2023/05/26/LaplacianMatrix/example_graph.png">
  
  
  
  <title>LaplacianMatrix - 努力减肥的小李</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"watsonlee.github.io","root":"/","version":"1.9.3","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":6},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"follow_dnt":true,"baidu":null,"google":null,"gtag":null,"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false}},"search_path":"/local-search.xml"};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  


  
<meta name="generator" content="Hexo 6.3.0"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>Watsonlee</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                Home
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                Archives
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                Categories
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                Tags
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                About
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              &nbsp;<i class="iconfont icon-search"></i>&nbsp;
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">&nbsp;<i
                class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/hanta1.png') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="LaplacianMatrix"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2023-05-26 23:06" pubdate>
          May 26, 2023 pm
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          9.1k words
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          76 mins
        
      </span>
    

    
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <!-- SEO header -->
            <h1 style="display: none">LaplacianMatrix</h1>
            
            
              <div class="markdown-body">
                
                <h1 id="图拉普拉斯矩阵的定义">1. 图拉普拉斯矩阵的定义</h1>
<p>给定图 <span class="math inline">\(\mathcal{G} = (\mathcal{V}, \mathcal{E})\)</span>，其拉普拉斯矩阵的定义如下： <span class="math display">\[ L = D - A = \begin{cases}
deg(i), &amp; i==j \\
-1, &amp; e_{ij} \in  \mathcal{E} \\
0, &amp; otherwise
\end{cases}\]</span> 其中 <span class="math inline">\(D\)</span> 表示度矩阵，<span class="math inline">\(A\)</span> 为邻接矩阵。我们可以看出，拉普拉斯矩阵主对角线第 <span class="math inline">\(i\)</span> 个矩阵表示第 <span class="math inline">\(i\)</span> 个节点的度， 即 <span class="math display">\[D_{ii} = \sum_{j} A_{ij}\]</span> 可以看出拉普拉斯矩阵是一个实对称阵，且行元素之和为0。</p>
<figure>
<img src="/2023/05/26/LaplacianMatrix/example_graph.png" srcset="/img/loading.gif" lazyload alt="图1 拓扑示例图"><figcaption aria-hidden="true">图1 拓扑示例图</figcaption>
</figure>
<p>对于图1，它的度矩阵<span class="math inline">\(D\)</span>，邻接矩阵<span class="math inline">\(A\)</span>和拉普拉斯矩阵<span class="math inline">\(L\)</span>分别为： <span class="math display">\[D=\left[ \begin{matrix}
2 &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; 2 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 3 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 1
\end{matrix}\right]\]</span> <span class="math display">\[A=\left[ \begin{matrix}
0 &amp; 1 &amp; 1 &amp; 0 \\
1 &amp; 0 &amp; 1 &amp; 0 \\
1 &amp; 1 &amp; 0 &amp; 1 \\
0 &amp; 0 &amp; 1 &amp; 0
\end{matrix}\right]\]</span> <span class="math display">\[L=\left[ \begin{matrix}
2 &amp; -1 &amp; -1 &amp; 0 \\
-1 &amp; 2 &amp; -1 &amp; 0 \\
-1 &amp; -1 &amp; 3 &amp; -1 \\
0 &amp; 0 &amp; -1 &amp; 1
\end{matrix}\right]\]</span></p>
<h1 id="拉普拉斯算子">2. 拉普拉斯算子</h1>
<p>拉普拉斯矩阵的定义来源于拉普拉斯算子，后者是 <span class="math inline">\(n\)</span> 维欧氏空间的二阶微分算子(用于计算散度) <span class="math display">\[\Delta f = \nabla^2 f = \nabla \cdot \nabla f = \sum_{i=1}^n \frac{\partial ^2 f}{\partial x_i^2}\]</span> 如果把图拉普拉斯矩阵看作是线性变换的话，它的作用与数学分析中的拉普拉斯算子是一样的。下面使用泰勒级数来推导。</p>
<p>首先假设离散空间最少单位步长单位 <span class="math inline">\(h\)</span>，即 <span class="math display">\[x_{i+1} - x_i = h\]</span> <span class="math display">\[x_i - x_{i-1} = h\]</span> 然后使用泰勒级数将函数 <span class="math inline">\(f(x_{i+1})\)</span> 和 <span class="math inline">\(f(x_{i-1})\)</span> 的函数值再 <span class="math inline">\(x_i\)</span> 处展开，可以得到： <span class="math display">\[f(x_{i+1}) = f(x_i) + f^{&#39;}(x_i)h + \frac{f^{&#39;&#39;}(x_i)}{2!}h^2 + O(h^2) \tag{1}\]</span> <span class="math display">\[f(x_{i-1}) = f(x_i) - f^{&#39;}(x_i)h + \frac{f^{&#39;&#39;}(x_i)}{2!}h^2 + O(h^2) \tag{2}\]</span> 如果直接求解 <span class="math inline">\(f^{&#39;}(x_i)\)</span>，其截断误差都是 <span class="math inline">\(O(h)\)</span>，为了进一步减小误差，可以使上下两式相减，可以得到 <span class="math display">\[f^{&#39;}(x_i) = \frac{f(x_{i+1})-f(x_{i-1})}{2} - O(h^2) \tag{3}\]</span> 可以看到，（3）式的误差变成了 <span class="math inline">\(O(h^2)\)</span>。利用同样的方法推导 <span class="math inline">\(f^{&#39;&#39;}(x_i)\)</span>，让（1）和（2）式相加，可以得到 <span class="math display">\[f^{&#39;&#39;}(x_i) = \frac{f(x_{i+1})+f(x_{i-1}) - 2f(x_i)}{h^2} - O(h^3) \tag{4}\]</span> 因此，可以将其表示为 <span class="math display">\[\Delta f = f(x_{i+1})+f(x_{i-1}) - 2f(x_i) \]</span> 如果将其离散到二维空间，就变成了边缘检测算子，描述中心像素与局部上下左右四个邻居之间的差异 <span class="math display">\[\Delta f(x,y) = \left[ f(x+1, y) + f(x-1, y) + f(x, y+1) + f(x, y-1) \right]-4 f(x,y)\tag{5}\]</span></p>
<p>如果在图信号中，拉普拉斯算子被用来描述中心节点和邻居节点之间的差异，</p>
<p><span class="math display">\[Lx= \left[ \begin{array}{c} 
\sum_{j\in \mathcal{N}(1)} (x_1 - x_j) \\
\sum_{j\in \mathcal{N}(2)} (x_2 - x_j) \\
\vdots \\
\sum_{j\in \mathcal{N}(n)} (x_n - x_j) \\
\end{array}\right] \]</span> 实际上拉普拉斯矩阵可以看做一个差分算子，第 <span class="math inline">\(i\)</span> 只与第 <span class="math inline">\(i\)</span> 个图节点及其一阶邻居节点有关，因此它反映了图信号局部平滑度的算子。</p>
<h1 id="normalized-laplacian-matrix">3. Normalized Laplacian Matrix</h1>
<p>为什么要对拉普拉斯矩阵做归一化呢？因为根据拉普拉斯矩阵进行计算时相当于采用加法规则，即把邻居节点的信息不断地聚合过来。这样就会导致度数大的节点特征会越来越大，而度数小的节点特征会越来越小。因此我们需要对拉普拉斯矩阵进行归一化。</p>
<h2 id="random-walk-based-normalization">3.1 Random Walk based Normalization</h2>
<p><span class="math display">\[L_{rw}=D^{-1}L = I - D^{-1}A = \frac{1}{D_{ii}} A_{ij} = \begin{cases} 
1 &amp; i=j \quad and \quad A_{ij} = 0  \\
\frac{-1}{D_{ii}} &amp; i \neq j \quad and \quad A_{ij}=1\\
0 &amp; i \neq j \quad and \quad A_{ij} = 0 
\end{cases} \tag{5}\]</span></p>
<p>以图1为例，它的归一化拉普拉斯矩阵为 <span class="math display">\[L_{rw}=\left[ \begin{matrix}
1 &amp; -\frac{1}{2} &amp; -\frac{1}{2} &amp; 0 \\
-\frac{1}{2} &amp; 1 &amp; -\frac{1}{2} &amp; 0 \\
-\frac{1}{3} &amp; -\frac{1}{3} &amp; 1 &amp; -\frac{1}{3} \\
0 &amp; 0 &amp; -1 &amp; 1
\end{matrix}\right]\]</span></p>
<p>我们可以看出，这种归一化方法的核心思想是对邻居求和取平均。但是我们可以看出来该方法得到的归一化矩阵不是对称的。而且这种方式仅考虑节点自身的度，没有考虑邻居节点的度。例如在更新节点<span class="math inline">\(v_2\)</span>的特征时，由于<span class="math inline">\(v_3\)</span>只与<span class="math inline">\(v_2\)</span>相连，而<span class="math inline">\(v_1\)</span>与<span class="math inline">\(v_2\)</span>和<span class="math inline">\(v_0\)</span>相连，显然<span class="math inline">\(v_3\)</span>对<span class="math inline">\(v_2\)</span>的忠诚度更高。</p>
<blockquote>
<p>解释：假如有A和B两个节点，A有1000个邻居，B只有A一个邻居。假定A对B的影响力和B对A的影响力是相同的，但是由于B只能接受A一个邻居的信息，A能接受1000个邻居节点的信息。 <em>但这里有一个疑问，按理说双方的影响力是不同的。不一定适合所有场景吧</em>。</p>
</blockquote>
<h2 id="symmetric-normalization">3.2 Symmetric Normalization</h2>
<p><span class="math display">\[L_{sym}=D^{-\frac{1}{2}}LD^{-\frac{1}{2}} = \begin{cases} 
1 &amp; i=j \quad and \quad A_{ij} = 0  \\
\frac{-1}{\sqrt{D_{ii} \cdot D_{jj}}} &amp; i \neq j \quad and \quad A_{ij}=1\\
0 &amp; i \neq j \quad and \quad A_{ij} = 0 
\end{cases} \tag{6}\]</span></p>
<p>从公式（6）中我们可以看出，对称归一化得到的拉普拉斯矩阵具有对称性，它同时考虑了自身和邻居节点的度。以图1为例，它的对称归一化拉普拉斯矩阵如下。</p>
<p><span class="math display">\[\begin{split}L_{sym}&amp;=D^{-\frac{1}{2}}LD^{-\frac{1}{2}}\\
&amp;= \left[\begin{matrix}
\frac{1}{\sqrt{2}} &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; \frac{1}{\sqrt{2}} &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; \frac{1}{\sqrt{3}} &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 1
\end{matrix}\right] \left[\begin{matrix}
2 &amp; -1 &amp; -1 &amp; 0 \\
-1 &amp; 2 &amp; -1 &amp; 0 \\
-1 &amp; -1 &amp; 3 &amp; -1 \\
0 &amp; 0 &amp; -1 &amp; 1
\end{matrix}\right] \left[\begin{matrix}
\frac{1}{\sqrt{2}} &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; \frac{1}{\sqrt{2}} &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; \frac{1}{\sqrt{3}} &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 1
\end{matrix}\right] \\
&amp;= \left[\begin{matrix}
\frac{1}{\sqrt{2}} &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; \frac{1}{\sqrt{2}} &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; \frac{1}{\sqrt{3}} &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 1
\end{matrix}\right] \left[\begin{matrix}
\frac{2}{\sqrt{2}} &amp; -\frac{1}{\sqrt{2}} &amp; -\frac{1}{\sqrt{3}} &amp; 0 \\
-\frac{1}{\sqrt{2}} &amp; \frac{2}{\sqrt{2}} &amp; -\frac{1}{\sqrt{3}} &amp; 0 \\
-\frac{1}{\sqrt{2}} &amp; -\frac{1}{\sqrt{2}} &amp; \frac{3}{\sqrt{3}} &amp; -1 \\
0 &amp; 0 &amp; -\frac{1}{\sqrt{3}} &amp; 1
\end{matrix}\right] \\
&amp;= \left[\begin{matrix}
1 &amp; -\frac{1}{2} &amp; - \frac{1}{\sqrt{3}} &amp; 0 \\
-\frac{1}{2} &amp; 1 &amp; -\frac{1}{\sqrt{6}} &amp; 0 \\
-\frac{1}{\sqrt{6}} &amp; -\frac{1}{\sqrt{6}} &amp; 1 &amp; \frac{1}{\sqrt{3}} \\
0 &amp; 0 &amp; -\frac{1}{\sqrt{3}} &amp; 1
\end{matrix}\right]
\end{split}\]</span></p>
<h2 id="对称归一化拉普拉斯矩阵的特征值">3.2.1 对称归一化拉普拉斯矩阵的特征值</h2>
<p><strong>结论</strong>：<span class="math inline">\(0=\lambda_0 &lt; \lambda_1 \le \lambda_2 \le \cdots \le \lambda_{max} = 2\)</span>。 当且仅当图G是二部图(bipartite)时，<span class="math inline">\(\lambda_{max}=2\)</span>。</p>
<p>证明：这里证明需要用到瑞利熵，<span class="math inline">\(R(A,x)=\frac{x^T A x}{x^T x}\)</span>，它具有如下性质 <span class="math inline">\(\lambda_{min} = min(R) \le R \le max(R) = \lambda_{max}\)</span>。对于<span class="math inline">\(L_{sym}\)</span>和任意向量<span class="math inline">\(g\)</span>，它们的瑞利熵可以表示为： <span class="math display">\[\begin{split}
R(L_{sym}, g)&amp;=\frac{g^T D^{-1/2} L D^{-1/2} g}{g^T g} = \frac{\left(D^{-1/2} g\right)^T L \left( D^{-1/2} g \right)}{g^T g} \\
&amp;= \frac{f^T L f}{\left( D^{1/2} f \right)^T \left( D^{1/2} f \right)} \\
&amp;= \frac{\sum_i f^2(i) d_i - \sum_i \sum_{j \land A_{ij}=1} f(i)(j)}{\sum_i f^2(i)d_i} \\
&amp;= \frac{\frac{1}{2} \left( \sum_i f^2(i)d_i + \sum_j f^2(j)d_j - \sum_i \sum_{j \land A_{ij}=1} 2f(i)(j) \right)}{\sum_i f^2(i)d_i} \\
&amp;= \frac{\frac{1}{2} \sum_i \sum_{j \land A_{ij}=1} (f(i) - f(j))^2}{\sum_i f^2(i)d_i} \\
&amp;=  \frac{\sum_{j \land A_{ij}=1} (f(i) - f(j))^2}{\sum_i f^2(i)d_i}
\end{split} \tag{8}\]</span></p>
<p>上式中，<span class="math inline">\(f\)</span>可以看作是每个节点上的信号函数。最后一行是因为节点<span class="math inline">\(i,j\)</span>互为邻居，既可以是 <span class="math inline">\(\sum_{j \land A_{ij}=1}\)</span>，也可以是 <span class="math inline">\(\sum_{j \land A_{ji}=1}\)</span>, 因此重复计算了。</p>
<p>根据公式(8)，我们可以看出 <span class="math inline">\(R(L_{sym},g) \ge 0\)</span>，且当 <span class="math inline">\(f(i)=f(j)\)</span> 时取等号。</p>
<ul>
<li>如果令 <span class="math inline">\(g=(\sqrt{d_1}, \sqrt{d_2}, \cdots, \sqrt{d_n})\)</span>，则 <span class="math inline">\(f = D^{-1/2} g = (1, 1, \cdots, 1)\)</span>。因此 0 是 <span class="math inline">\(L_{sym}\)</span> 的最小特征值。</li>
<li>因为 <span class="math inline">\((f(i) - f(j))^2 \le 2(f^2(i) + f^2(j))\)</span>，因此我们可以得到<span class="math inline">\(R(L_{sym}, g) = \frac{\sum_{j \land A_{ij}=1} (f(i) - f(j))^2}{\sum_i f^2(i)d_i} \le \frac{2\sum_{j \land A_{ij}=1} (f(i) + f(j))^2}{\sum_i f^2(i)d_i} = 2\)</span></li>
</ul>
<p>取得等于号的条件是对于任意的 <span class="math inline">\(f(x) + f(y) = 0\)</span>。根据二部图的定义，如果G为二部图，那么G至少有两个顶点，且其所有回路长度均为偶数。套用该条件，假定二部图左侧均为正，右侧均为负，满足条件。</p>
<h1 id="拉普拉斯矩阵与图神经网络">4. 拉普拉斯矩阵与图神经网络</h1>
<p>最开始的图卷积网络是基于谱域思想的，作者将图的拉普拉斯矩阵的特征向量作为基底，然后将样本变换到谱域空间后，再对不同频率的信息进行操作，最后再从谱域变换回来。核心是设计频率响应矩阵，对频率响应矩阵进行参数化，通过训练的方式来让图滤波器（图卷积）自动地调整和取舍不同频段的信息，从而提取出有用的特征。但该方法依赖于矩阵分解，且每一步都要做傅里叶变换和逆变换，计算开销过大。而且，根据研究成果，图中的有效信息往往蕴含在低频段，没有必要为每个频段训练一个参数。</p>
<blockquote>
<p>这里低频与高频主要是指小的特征值与大的特征值对应的频段。</p>
</blockquote>
<p>之后， Kipf等人不再花费大量的时间去求特征值，改为直接在节点层面进行滤波操作。它们将节点层面的滤波定义为： 某个节点K阶子图上所有节点（包括自身）的信号值的线性组合。 <span class="math display">\[f_{out}(i) = b_{i,i} f_{in}(i) + \sum_{j\in \mathcal{N}(i,K)} b_{i,j} f_{in}(j) \tag{9}\]</span> 公式（9）中<span class="math inline">\(\mathcal{N}(i,K)\)</span> 表示节点<span class="math inline">\(i\)</span>的第1阶至第K阶邻居节点。当频率响应函数是K阶多项式时，节点<span class="math inline">\(i\)</span>在频域内的滤波结果是周围1至K阶邻居节点信号值的线性组合，文献[1]中有详细的解释。可以直接使用拉普拉斯矩阵的多项式函数来逼近任意一个滤波器，甚至，不去计算特征值，利用切比雪夫多项式近似法。</p>
<p>切比雪夫多项式来源于n倍角公式，每一项可以通过迭代的方式得到，第K项满足 <span class="math display">\[T_k(x) = 2x T_{k-1}(x) - T_{k-2}(x), T_0 = 1, T_1 = x \tag{10}\]</span> 于是，可以使用截断的K阶切比雪夫多项式来表示图卷积操作： <span class="math display">\[g_\theta(\Lambda) = \sum_{k=0}^K \theta_k T_k(\overline{\Lambda}), \overline{\Lambda} = \frac{2\Lambda}{\lambda_{max}} - I_n \tag{11}\]</span> 将特征值进行缩放和偏移处理的目的是为了让其范围为[-1, 1]，从而使卷积操作成为一种压缩映射，避免堆叠多层导致某些频段信号被指数级放大。</p>
<p>滤波之后的图信号为： <span class="math display">\[y = g_\theta(\overline{L})x = \sum_{k=0}^K \theta_k T_k (\overline{L})x \overline{L} = \frac{2L_{sym}}{\lambda_{max}} - I_n \tag{12}\]</span></p>
<p>前文证明过，<span class="math inline">\(L_{sym}\)</span>的特征值范围为[0,2]，因此经过放缩之后，特征值的范围为[-1, 1]。</p>
<h1 id="重归一化拉普拉斯矩阵与gcn">5 重归一化拉普拉斯矩阵与GCN</h1>
<h2 id="动机">5.1 动机</h2>
<p>在实际应用场景中，如果K值取值过高，那么对于包含度数较大的节点的图来说，一个卷积层的感受野很有可能覆盖几乎整张图，这样的话，即使堆叠了几层卷积层，后续卷积层的感受野仍然是整张图，重复执行全局平均操作，最终会导致输出图信号过平滑。</p>
<p>为了缩小每一层的感受野，同时降低每一层的计算量，我们固定K=1， 根据归一化拉普拉斯矩阵的最大特征值为<span class="math inline">\(\lambda_{max} \approx 2\)</span>，得到一阶近似切比雪夫多项式： <span class="math display">\[y=\theta_0 x + \theta_1 (L-I_n)x = \theta_0 x - \theta_1 D^{-1/2} A D^{-1/2} x \tag{13} \]</span> 为了参数统一，设<span class="math inline">\(\theta_0 = - \theta_1 = \theta\)</span>, 则可以得到 <span class="math display">\[y = \theta(I_n + D^{-1/2}A D^{-1/2}) x = Hx \tag{14}\]</span> 由于 $I_n + D^{-1/2}A D^{-1/2} = I_n + D^{-1/2}(I_n - L)D^{-1/2} = 2I_n - L_{sym} $，它的特征值范围是[0,2]，连读堆叠这样的卷积层相当于引入了频率响应函数 <span class="math inline">\((2-\lambda_i)^K\)</span>，会过度放大 <span class="math inline">\(\lambda_i &lt;1\)</span> 频段的信号，进而引发某些参数梯度爆炸，另外一些参数梯度消失。</p>
<h2 id="方法">5.2 方法</h2>
<p>为此，Kipf等人提出了重归一化操作（Renormalization Trick），为每个节点加上自环，得到新的邻接矩阵和度矩阵： <span class="math display">\[\tilde{A} = A+I_n, \tilde{D} = D+I_n \tag{15}\]</span> 此时，归一化拉普拉斯矩阵变为： <span class="math display">\[\tilde{L}_{sym} = \tilde{D}^{-1/2}(\tilde{D} - \tilde{A}) \tilde{D}^{-1/2} = \tilde{D}^{-1/2} L \tilde{D}^{-1/2} \]</span> 使用单位阵减去<span class="math inline">\(\tilde{L}_{sym}\)</span>，可以得到： <span class="math display">\[L_{renorm} = I_n - \tilde{D}^{-1/2} L \tilde{D}^{-1/2} = \tilde{D}^{-1/2} \tilde{A} \tilde{D}^{-1/2} \tag{16}\]</span> 因为公式（16）可以重写为 <span class="math display">\[L_{renorm} = I_n - \tilde{L}_{sym} = \tilde{U}^T I_n \tilde{U} - \tilde{U}^T \tilde{\Lambda} \tilde{U} = \tilde{U}^T (I_n - \tilde{\Lambda}) \tilde{U} \tag{17}\]</span> 因此，<span class="math inline">\(L_{renorm}\)</span>的频率响应函数为 <span class="math inline">\((1-\tilde{\lambda}_i)^K\)</span>，解决了低频段信号被过度放大的问题。</p>
<h2 id="优势">5.3 优势</h2>
<p>本文中提到了以下三种归一化矩阵：</p>
<ul>
<li><p>归一化邻接矩阵 <span class="math inline">\(D^{-1/2} A D^{-1/2}\)</span>，未加自环，频率响应函数为 <span class="math inline">\((1-\lambda_i)^K\)</span></p></li>
<li><p>一阶近似切比雪夫多项式 <span class="math inline">\(I_n + D^{-1/2} W D^{-1/2}\)</span>的频率响应函数 <span class="math inline">\((2 - \tilde{\lambda}_i)^K\)</span></p></li>
<li><p>重归一化拉普拉斯矩阵 <span class="math inline">\(\tilde{D}^{-1/2} \tilde{A} \tilde{D}^{-1/2}\)</span> 的频率响应函数 <span class="math inline">\((1 - \tilde{\lambda}_i)^K\)</span></p></li>
</ul>
<p>上述三者的特征值范围都是[0,2)，唯一的区别是，加入了自环之后，重归一化拉普拉斯矩阵的最大特征值小于归一化拉普拉斯矩阵的最大特征值，即 <span class="math display">\[0 = \lambda_1 = \tilde{\lambda}_1 &lt; \tilde{\lambda}_n &lt; \lambda_n &lt; 2 \tag{18}\]</span> 公式（18）的证明可以参考 <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1902.07153v1.pdf">Simplifying Graph Convolutional Networks</a> 一文附录中关于Theorem 1 的证明。</p>
<figure>
<img src="/2023/05/26/LaplacianMatrix/eigenvalue_of_diff_matrix.png" srcset="/img/loading.gif" lazyload alt="图2 特征值的谱域分布"><figcaption aria-hidden="true">图2 特征值的谱域分布</figcaption>
</figure>
<p>最左侧是一阶近似切比雪夫多项式方法，它过度放大了低频信号；中间是未加自环的归一化拉普拉斯矩阵，它不存在过度放大低频信号的问题，但它却放大了高频信号的强度，以及当阶数为奇数时，放大系数为负数；最后一个是重归一化拉普拉斯矩阵的频率响应函数，由于最大特征值被压缩了，所以过度放大问题被解决了。</p>
<p>因此可以用 <span class="math inline">\(L_{renorm}\)</span> 为核心设计图卷积层： <span class="math display">\[Z = \sigma \left( \tilde{D}^{-1/2} \tilde{W} \tilde{D}^{-1/2} X \Theta \right), where \quad \Theta\in\mathbb{R}^{f_{in} \times f_{out}} \quad and \quad Z \in \mathbb{R}^{N\times f_{out}} \tag{19}\]</span> 公式（19）中X为如向量信号，<span class="math inline">\(\Theta\)</span>是可训练的线性变换，用户表示通道映射。</p>
<h1 id="参考">参考</h1>
<ol type="1">
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/297613044">图卷积网络原来是这么回事 - Cosmic being的文章 - 知乎</a></li>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/65447367">图的拉普拉斯矩阵的特征值范围的一个估计 - 小明教主的文章 - 知乎</a></li>
<li><a target="_blank" rel="noopener" href="https://blog.csdn.net/zfhsfdhdfajhsr/article/details/124552753">【图神经网络基础】理解GCN的对称归一化操作-图的拉普拉斯归一化 - 一穷二白到年薪百万</a></li>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/412337460">对称归一化拉普拉斯矩阵的意义 - 马东什么的文章 - 知乎</a></li>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/142640571">GCN 为什么是低通滤波器？具体在干啥？ - yang lebron的文章 - 知乎</a></li>
</ol>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
    <div class="post-meta mr-3 d-flex align-items-center">
      <i class="iconfont icon-category"></i>
      

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/" class="category-chain-item">基础知识</a>
  
  
    <span>></span>
    
  <a href="/categories/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" class="category-chain-item">图神经网络</a>
  
  

  

      </span>
    
  
</span>

    </div>
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/tags/%E6%8B%89%E6%99%AE%E6%8B%89%E6%96%AF%E7%9F%A9%E9%98%B5/">#拉普拉斯矩阵</a>
      
        <a href="/tags/%E5%9B%BE%E6%AD%A3%E5%88%99%E5%8C%96/">#图正则化</a>
      
    </div>
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>LaplacianMatrix</div>
      <div>http://watsonlee.github.io/2023/05/26/LaplacianMatrix/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>Author</div>
          <div>Huacheng Li</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>Posted on</div>
          <div>May 26, 2023</div>
        </div>
      
      
      
        <div class="license-meta-item">
          <div>Licensed under</div>
          <div>
            
              
              
                <a target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - Attribution">
                    <i class="iconfont icon-by"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2023/06/08/Hexo%E5%8D%9A%E5%AE%A2%E8%BF%81%E7%A7%BB/" title="Hexo博客迁移">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">Hexo博客迁移</span>
                        <span class="visible-mobile">Previous</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2023/02/28/VariationalInference/" title="变分推断">
                        <span class="hidden-mobile">变分推断</span>
                        <span class="visible-mobile">Next</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;Table of Contents</p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  


  
  









    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">Search</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">Keyword</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
    </div>
  
  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.0/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.18.2/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  
      <script>
        if (!window.MathJax) {
          window.MathJax = {
            tex    : {
              inlineMath: { '[+]': [['$', '$']] }
            },
            loader : {
              load: ['ui/lazy']
            },
            options: {
              renderActions: {
                insertedScript: [200, () => {
                  document.querySelectorAll('mjx-container').forEach(node => {
                    let target = node.parentNode;
                    if (target.nodeName.toLowerCase() === 'li') {
                      target.parentNode.classList.add('has-jax');
                    }
                  });
                }, '', false]
              }
            }
          };
        } else {
          MathJax.startup.document.state(0);
          MathJax.texReset();
          MathJax.typeset();
          MathJax.typesetPromise();
        }

        Fluid.events.registerRefreshCallback(function() {
          if ('MathJax' in window && MathJax.startup.document && typeof MathJax.startup.document.state === 'function') {
            MathJax.startup.document.state(0);
            MathJax.texReset();
            MathJax.typeset();
            MathJax.typesetPromise();
          }
        });
      </script>
    

  <script  src="https://lib.baomitu.com/mathjax/3.2.2/es5/tex-mml-chtml.js" ></script>

  <script  src="/js/local-search.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">Blog works best with JavaScript enabled</div>
  </noscript>
</body>
</html>
